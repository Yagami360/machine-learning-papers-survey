> è«–æ–‡ã¾ã¨ã‚ï¼šhttps://github.com/Yagami360/MachineLearning-Papers_Survey/issues/4

# â–  è«–æ–‡
- è«–æ–‡ã‚¿ã‚¤ãƒˆãƒ«ï¼š"Face Swapping: Realistic Image Synthesis Based on Facial Landmarks Alignment"
- è«–æ–‡ãƒªãƒ³ã‚¯ï¼šhttp://downloads.hindawi.com/journals/mpe/2019/8902701.pdf
- è«–æ–‡æŠ•ç¨¿æ—¥ä»˜ï¼š2019/3/14
- è‘—è€…ï¼ˆçµ„ç¹”ï¼‰ï¼š
- categoriesï¼š

# â–  æ¦‚è¦ï¼ˆä½•ã‚’ã—ãŸã‹ï¼Ÿï¼‰

## Abstract

- We propose an image-based face swapping algorithm, which can be used to replace the face in the reference image with the same facial shape and features as the input face. 
    - ç”»åƒãƒ™ãƒ¼ã‚¹ã®é¡”ã‚¹ãƒ¯ãƒƒãƒ”ãƒ³ã‚°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ç”¨ã—ã¦ã€å‚ç…§ç”»åƒã®é¡”ã‚’å…¥åŠ›é¡”ã¨åŒã˜é¡”ã®å½¢ã¨ç‰¹å¾´ã«ç½®ãæ›ãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

- First, a face alignment is made based on a group of detected facial landmarks, so that the aligned input face and the reference face are consistent in size and posture. Secondly, an image warping algorithm based on triangulation is presented to adjust the reference face and its background according to the aligned input faces. 
    - ã¾ãšã€æ¤œå‡ºã•ã‚ŒãŸé¡”ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®ã‚°ãƒ«ãƒ¼ãƒ—ã«åŸºã¥ã„ã¦é¡”ã®ä½ç½®åˆã‚ã›ãŒè¡Œã‚ã‚Œã€ä½ç½®åˆã‚ã›ã•ã‚ŒãŸå…¥åŠ›é¡”ã¨åŸºæº–é¡”ã®ã‚µã‚¤ã‚ºã¨å§¿å‹¢ãŒä¸€è‡´ã—ã¾ã™ã€‚æ¬¡ã«ã€ä¸‰è§’æ¸¬é‡ã«åŸºã¥ãç”»åƒãƒ¯ãƒ¼ãƒ”ãƒ³ã‚°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’æç¤ºã—ã¦ã€æ•´åˆ—ã—ãŸå…¥åŠ›é¢ã«å¿œã˜ã¦å‚ç…§é¢ã¨ãã®èƒŒæ™¯ã‚’èª¿æ•´ã—ã¾ã™ã€‚

- In order to achieve more accurate face swapping, a face parsing algorithm is introduced to realize the accurate detection of the face-ROIs, and then the face-ROI in the reference image is replaced with the input face-ROI.
    - ã‚ˆã‚Šæ­£ç¢ºãªé¡”ã‚¹ãƒ¯ãƒƒãƒ”ãƒ³ã‚°ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã€é¡”è§£æã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å°å…¥ã—ã¦é¡”ROIã®æ­£ç¢ºãªæ¤œå‡ºã‚’å®Ÿç¾ã—ã€ãã®å¾Œã€å‚ç…§ç”»åƒå†…ã®é¡”ROIã‚’å…¥åŠ›é¡”ROIã«ç½®ãæ›ãˆã¾ã™ã€‚

- Finally, a Poisson image editing algorithm is adopted to realize the boundary processing and color correction between the replacement region and the original background, and then the final face swapping result is obtained.  
    - æœ€å¾Œã«ã€ãƒã‚¢ã‚½ãƒ³ç”»åƒç·¨é›†ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’æ¡ç”¨ã—ã¦ã€ç½®æ›é ˜åŸŸã¨å…ƒã®èƒŒæ™¯ã¨ã®é–“ã®å¢ƒç•Œå‡¦ç†ã¨è‰²è£œæ­£ã‚’å®Ÿç¾ã—ã€æœ€çµ‚çš„ãªé¡”ã‚¹ãƒ¯ãƒƒãƒ”ãƒ³ã‚°çµæœã‚’å–å¾—ã—ã¾ã™ã€‚

- In the experiments, we compare our method with other face swapping algorithms and make a qualitative and quantitative analysis to evaluate the reality and the fidelity of the replaced face. The analysis results show that our method has some advantages in the overall performance of swapping effect.  
    - å®Ÿé¨“ã§ã¯ã€ã“ã®æ–¹æ³•ã¨ä»–ã®é¡”äº¤æ›ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’æ¯”è¼ƒã—ã€å®šæ€§çš„ãŠã‚ˆã³å®šé‡çš„ãªåˆ†æã‚’è¡Œã£ã¦ã€ç½®ãæ›ãˆã‚‰ã‚ŒãŸé¡”ã®ç¾å®Ÿã¨å¿ å®Ÿåº¦ã‚’è©•ä¾¡ã—ã¾ã™ã€‚åˆ†æçµæœã¯ã€æœ¬æ‰‹æ³•ãŒã‚¹ãƒ¯ãƒƒãƒ”ãƒ³ã‚°åŠ¹æœã®å…¨ä½“çš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ã„ãã¤ã‹ã®åˆ©ç‚¹ãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚

# â–  ã‚¤ãƒ³ãƒˆãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆä½•ã‚’ã—ãŸã„ã‹ï¼Ÿï¼‰

## 1. Introduction

- Face synthesis refers to the image processing technology of the automatic fusion of two or more different faces into one face, which is widely used in fields of video synthesis, privacy protection, picture enhancement, and entertainment applications. For example, when we want to share some of the interesting things on social networks, we can use the face synthesis technique which can be regarded as a fusion of facial features and details to change our appearances appropriately without privacy leaks. As another type of face fusion, face swapping combines some parts of one personâ€™s face with other parts of the otherâ€™s face to form a new face image. For instance, in the application of virtual hairstyle visualization, the clientâ€™s facial area can be fused with the hair areas of the model images to form new photos, so that customers can virtually browse their own figures with different hairstyles.
    - é¡”åˆæˆã¨ã¯ã€2ã¤ä»¥ä¸Šã®ç•°ãªã‚‹é¡”ã‚’1ã¤ã®é¡”ã«è‡ªå‹•çš„ã«èåˆã™ã‚‹ç”»åƒå‡¦ç†æŠ€è¡“ã‚’æŒ‡ã—ã¾ã™ã€‚ã“ã‚Œã¯ã€ãƒ“ãƒ‡ã‚ªåˆæˆã€ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·ã€ç”»åƒå¼·èª¿ã€ãŠã‚ˆã³ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ†ã‚¤ãƒ¡ãƒ³ãƒˆã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®åˆ†é‡ã§åºƒãä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚ãŸã¨ãˆã°ã€ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¸Šã§èˆˆå‘³æ·±ã„ã‚‚ã®ã‚’å…±æœ‰ã—ãŸã„å ´åˆã€é¡”ã®ç‰¹å¾´ã¨è©³ç´°ã®èåˆã¨è¦‹ãªã™ã“ã¨ãŒã§ãã‚‹é¡”åˆæˆæŠ€è¡“ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒªãƒ¼ã‚¯ãªã—ã«å¤–è¦³ã‚’é©åˆ‡ã«å¤‰æ›´ã§ãã¾ã™ã€‚åˆ¥ã®ã‚¿ã‚¤ãƒ—ã®é¡”ã®èåˆã¨ã—ã¦ã€é¡”ã®å…¥ã‚Œæ›¿ãˆã¯ã€ã‚ã‚‹äººã®é¡”ã®ä¸€éƒ¨ã‚’ä»–ã®äººã®é¡”ã®ä»–ã®éƒ¨åˆ†ã¨çµ„ã¿åˆã‚ã›ã¦ã€æ–°ã—ã„é¡”ç”»åƒã‚’å½¢æˆã—ã¾ã™ã€‚ãŸã¨ãˆã°ã€ä»®æƒ³ãƒ˜ã‚¢ã‚¹ã‚¿ã‚¤ãƒ«ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®é¡”ã®é ˜åŸŸã‚’ãƒ¢ãƒ‡ãƒ«ç”»åƒã®ãƒ˜ã‚¢é ˜åŸŸã¨èåˆã—ã¦æ–°ã—ã„å†™çœŸã‚’ä½œæˆã§ãã‚‹ãŸã‚ã€é¡§å®¢ã¯ã•ã¾ã–ã¾ãªãƒ˜ã‚¢ã‚¹ã‚¿ã‚¤ãƒ«ã§è‡ªåˆ†ã®ãƒ•ã‚£ã‚®ãƒ¥ã‚¢ã‚’ä»®æƒ³çš„ã«é–²è¦§ã§ãã¾ã™ã€‚

- This paper focuses on the face swapping problem of virtual browsing applications for hairstyle and dressing. 
    - ã“ã®ãƒ›ãƒ¯ã‚¤ãƒˆãƒšãƒ¼ãƒ‘ãƒ¼ã§ã¯ã€ãƒ˜ã‚¢ã‚¹ã‚¿ã‚¤ãƒ«ã¨ãƒ‰ãƒ¬ãƒƒã‚·ãƒ³ã‚°ã®ãŸã‚ã®ä»®æƒ³ãƒ–ãƒ©ã‚¦ã‚¸ãƒ³ã‚°ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®é¡”äº¤æ›å•é¡Œã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚
    
- Our main contributions of the proposed algorithm include the following: (1) construct a pipeline of face swapping which integrates some learning-based modules into the traditional replacement- based approach, (2) improve the sense of reality and reliability of the synthesis face based on the precise detection of the facial landmarks, and (3) the face occlusion problem can be solved by introducing an accurate face parsing algorithm.
    - **ææ¡ˆã•ã‚ŒãŸã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ä¸»ãªè²¢çŒ®ã¯æ¬¡ã®ã¨ãŠã‚Šã§ã™ã€‚**
    - ï¼ˆ1ï¼‰ã„ãã¤ã‹ã®å­¦ç¿’ãƒ™ãƒ¼ã‚¹ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å¾“æ¥ã®ç½®æ›ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«çµ±åˆã™ã‚‹é¡”äº¤æ›ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚
    -  **ï¼ˆ2ï¼‰é¡”ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®æ­£ç¢ºãªæ¤œå‡ºã‚’å…ƒã«åˆæˆé¡”ã®ç¾å®Ÿæ„Ÿã¨ä¿¡é ¼æ€§ã‚’æ”¹å–„ã—ã¾ã™ã€‚**
    -  **ï¼ˆ3ï¼‰é¡”ã®é–‰å¡å•é¡Œã¯ã€æ­£ç¢ºãªé¡”è§£æã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å°å…¥ã™ã‚‹ã“ã¨ã§è§£æ±ºã§ãã¾ã™ã€‚**


# â–  çµè«–

## 5. Conclusion

- In this paper, a new face swapping algorithm based on facial landmarks detection is proposed, which can achieve fast, stable, and robust face replacement without the three- dimensional model. Our approach introduces the training results of existing learning models directly. The method we proposed does not require any training data, because it uses no learning model for new training.
    - **æœ¬è«–æ–‡ã§ã¯ã€é¡”ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æ¤œå‡ºã«åŸºã¥ã„ãŸæ–°ã—ã„é¡”äº¤æ›ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã‚Œã¯ã€3æ¬¡å…ƒãƒ¢ãƒ‡ãƒ«ãªã—ã§é«˜é€Ÿã€å®‰å®šã€å …ç‰¢ãªé¡”ã®ç½®æ›ã‚’å®Ÿç¾ã§ãã¾ã™ã€‚** ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯ã€æ—¢å­˜ã®å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çµæœã‚’ç›´æ¥ç´¹ä»‹ã—ã¾ã™ã€‚**ææ¡ˆã—ãŸæ–¹æ³•ã¯ã€æ–°ã—ã„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãªã„ãŸã‚ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’å¿…è¦ã¨ã—ã¾ã›ã‚“ã€‚**

- The experimental results show that the composite image obtained by our model has a great reality and strong adaptability to the difference of skin color and hair occlusion while retaining most of the facial features of the input image. Compared with other algorithms, our model has some advantages in aspects of visual realism, time complexity, and data requirement.
    - å®Ÿé¨“çµæœã¯ã€æˆ‘ã€…ã®ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦å¾—ã‚‰ã‚ŒãŸåˆæˆç”»åƒã¯ã€å…¥åŠ›ç”»åƒã®é¡”ã®ç‰¹å¾´ã®ã»ã¨ã‚“ã©ã‚’ä¿æŒã—ãªãŒã‚‰ã€è‚Œã®è‰²ã¨é«ªã®é–‰å¡ã®é•ã„ã«å¤§ããªç¾å®Ÿæ€§ã¨å¼·ã„é©å¿œæ€§ã‚’æŒã£ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ ä»–ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¨æ¯”è¼ƒã—ã¦ã€ã“ã®ãƒ¢ãƒ‡ãƒ«ã«ã¯è¦–è¦šçš„ãƒªã‚¢ãƒªã‚ºãƒ ã€æ™‚é–“ã®è¤‡é›‘ã•ã€ãƒ‡ãƒ¼ã‚¿è¦ä»¶ã®é¢ã§ã„ãã¤ã‹ã®åˆ©ç‚¹ãŒã‚ã‚Šã¾ã™ã€‚

- However, there is still room for further improvement, which mainly shows that the swapping result is not perfect when the input face and the reference face have a significant difference in perspective and posture. How to predict and generate the face image from a given perspective to another one is essential to solving the problem and also the main direction of our future research.
    - **ãŸã ã—ã€å…¥åŠ›é¢ã¨å‚ç…§é¢ã®è¦–ç‚¹ã¨å§¿å‹¢ã«å¤§ããªé•ã„ãŒã‚ã‚‹å ´åˆã€ä¸»ã«ã‚¹ãƒ¯ãƒƒãƒ”ãƒ³ã‚°ã®çµæœãŒå®Œå…¨ã§ã¯ãªã„ã“ã¨ã‚’ä¸»ã«ç¤ºã™ã€ã•ã‚‰ãªã‚‹æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚Šã¾ã™ã€‚** å•é¡Œã‚’è§£æ±ºã—ã€ä»Šå¾Œã®ç ”ç©¶ã®ä¸»ãªæ–¹å‘æ€§ã‚’è§£æ±ºã™ã‚‹ã«ã¯ã€ç‰¹å®šã®è¦–ç‚¹ã‹ã‚‰åˆ¥ã®è¦–ç‚¹ã¾ã§é¡”ç”»åƒã‚’äºˆæ¸¬ãŠã‚ˆã³ç”Ÿæˆã™ã‚‹æ–¹æ³•ãŒä¸å¯æ¬ ã§ã™ã€‚

# â–  ä½•ã‚’ã—ãŸã‹ï¼Ÿè©³ç´°

## 3. Method

- The algorithm is composed of three steps: face alignment, warping and replacement. The accuracy and robustness of the algorithm are enhanced by introducing some learning-based modules like facial landmark detection and face parsing.
    - ã“ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ã€é¡”ã®ä½ç½®åˆã‚ã›ã€ãƒ¯ãƒ¼ãƒ—ã€ãŠã‚ˆã³ç½®æ›ã®3ã¤ã®ã‚¹ãƒ†ãƒƒãƒ—ã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚ ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ç²¾åº¦ã¨å …ç‰¢æ€§ã¯ã€é¡”ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®æ¤œå‡ºã‚„é¡”ã®è§£æãªã©ã®å­¦ç¿’ãƒ™ãƒ¼ã‚¹ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å°å…¥ã™ã‚‹ã“ã¨ã§å¼·åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚

### 3.1.PipelineofFaceSwapping.

![image](https://user-images.githubusercontent.com/25688193/63206266-64f36b80-c0ec-11e9-8d2a-e18d02e4d86b.png)

- Although face swapping seems uncomplicated and practicable, an elaborately designed algorithm flow still has an impact on the realization of the final result. The pipeline of the proposed algorithm starts with two channels that finally fuse into one, as shown in Figure 1.
- First, the input image is aligned with the reference image based on a facial landmark detection algorithm.
- Second, the reference image is warped to fit the aligned face of the input image. With an advanced face parsing algorithm, in the next step, the face-ROIs are extracted from the aligned input image and the warped reference image, respectively.
- Finally, some common steps of face replacement and color correction are introduced to generate the final composite face image.
- To summarize, the proposed algorithm will be demonstrated into three parts: face alignment, face warping, and face replacement.
    - é¡”ã®äº¤æ›ã¯è¤‡é›‘ã§å®Ÿç”¨çš„ã§ã¯ãªã„ã‚ˆã†ã«è¦‹ãˆã¾ã™ãŒã€ç²¾å·§ã«è¨­è¨ˆã•ã‚ŒãŸã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒ•ãƒ­ãƒ¼ã¯ã€æœ€çµ‚çµæœã®å®Ÿç¾ã«ä¾ç„¶ã¨ã—ã¦å½±éŸ¿ã‚’åŠã¼ã—ã¾ã™ã€‚ ææ¡ˆã•ã‚ŒãŸã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯ã€å›³1ã«ç¤ºã™ã‚ˆã†ã«ã€æœ€çµ‚çš„ã«1ã¤ã«èåˆã™ã‚‹2ã¤ã®ãƒãƒ£ãƒãƒ«ã‹ã‚‰å§‹ã¾ã‚Šã¾ã™ã€‚
    - æœ€åˆã«ã€é¡”ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æ¤œå‡ºã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«åŸºã¥ã„ã¦å…¥åŠ›ç”»åƒã‚’å‚ç…§ç”»åƒã«åˆã‚ã›ã¾ã™ã€‚ 
    - ç¬¬äºŒã«ã€å‚ç…§ç”»åƒã¯å…¥åŠ›ç”»åƒã®æ•´åˆ—ã•ã‚ŒãŸé¡”ã«åˆã†ã‚ˆã†ã«ãƒ¯ãƒ¼ãƒ—ã•ã‚Œã¾ã™ã€‚ é«˜åº¦ãªé¡”è§£æã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã€é¡”ã®ROI [region of interest] ãŒä½ç½®åˆã‚ã›ã•ã‚ŒãŸå…¥åŠ›ç”»åƒã¨ãƒ¯ãƒ¼ãƒ—ã•ã‚ŒãŸå‚ç…§ç”»åƒã‹ã‚‰ãã‚Œãã‚ŒæŠ½å‡ºã•ã‚Œã¾ã™ã€‚
    - æœ€å¾Œã«ã€æœ€çµ‚çš„ãªåˆæˆé¡”ç”»åƒã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã«ã€é¡”ã®ç½®æ›ã¨è‰²è£œæ­£ã®ã„ãã¤ã‹ã®ä¸€èˆ¬çš„ãªæ‰‹é †ãŒå°å…¥ã•ã‚Œã¾ã™ã€‚
    - è¦ç´„ã™ã‚‹ã¨ã€ææ¡ˆã•ã‚ŒãŸã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ã€é¡”ã®ä½ç½®åˆã‚ã›ã€é¡”ã®ã‚†ãŒã¿ã€é¡”ã®ç½®æ›ã®3ã¤ã®éƒ¨åˆ†ã«åˆ†ã‹ã‚Œã¦ã„ã¾ã™ã€‚

### 3.2. Face Alignment.

- As the first step of face swapping, alignment refers to aligning the input face image ğ¼in and the reference face image ğ¼ref in size and direction. For the purpose of detecting faces in pictures, we apply the relevant methods in paper [14] which proposes a novel multiple sparse representation framework for visual tracking to detect the faces in pictures. Apart from increasing the speed of the algorithm, the application of sparse coding and dictionary learning also enables these methods to learn more knowledge from relatively fewer sample data. Then we extract several stable key points from the images to mark the faces, referred to as facial landmark detection (FLD for short).
    - é¡”ã‚¹ãƒ¯ãƒƒãƒ”ãƒ³ã‚°ã®æœ€åˆã®ã‚¹ãƒ†ãƒƒãƒ—ã¨ã—ã¦ã€ä½ç½®åˆã‚ã›ã¯ã€å…¥åŠ›é¡”ç”»åƒğ¼inã¨å‚ç…§é¡”ç”»åƒğ¼refã®ã‚µã‚¤ã‚ºã¨æ–¹å‘ã®ä½ç½®åˆã‚ã›ã‚’æŒ‡ã—ã¾ã™ã€‚ å†™çœŸå†…ã®é¡”ã‚’æ¤œå‡ºã™ã‚‹ãŸã‚ã«ã€è¦–è¦šè¿½è·¡ç”¨ã®æ–°ã—ã„è¤‡æ•°ã®ã‚¹ãƒ‘ãƒ¼ã‚¹è¡¨ç¾ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã™ã‚‹å†™çœŸ[14]ã®é–¢é€£ã™ã‚‹æ–¹æ³•ã‚’é©ç”¨ã—ã¦ã€å†™çœŸå†…ã®é¡”ã‚’æ¤œå‡ºã—ã¾ã™ã€‚ ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®é€Ÿåº¦ã‚’ä¸Šã’ã‚‹ã ã‘ã§ãªãã€ã‚¹ãƒ‘ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¨è¾æ›¸å­¦ç¿’ã‚’é©ç”¨ã™ã‚‹ã“ã¨ã«ã‚ˆã‚Šã€ã“ã‚Œã‚‰ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯æ¯”è¼ƒçš„å°‘ãªã„ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚ˆã‚Šå¤šãã®çŸ¥è­˜ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚ æ¬¡ã«ã€é¡”ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æ¤œå‡ºï¼ˆç•¥ã—ã¦FLDï¼‰ã¨å‘¼ã°ã‚Œã‚‹ã€ç”»åƒã‹ã‚‰ã„ãã¤ã‹ã®å®‰å®šã—ãŸã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚’æŠ½å‡ºã—ã¦é¡”ã‚’ãƒãƒ¼ã‚¯ã—ã¾ã™ã€‚

- In this paper, we employ a popular FLD algorithm [9, 15] based on an ensemble of regression trees to detect facial landmarks Î©s = {ğ‘ ğ‘– | ğ‘– = 1,2,...,68}, as plotted in Figure 2(a).
    - ã“ã®è«–æ–‡ã§ã¯ã€å›å¸°ãƒ„ãƒªãƒ¼ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã«åŸºã¥ã„ãŸä¸€èˆ¬çš„ãªFLDã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ [9ã€15]ã‚’ä½¿ç”¨ã—ã¦ã€é¡”ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’æ¤œå‡ºã—ã¾ã™ã€‚ ğ‘–= 1,2ã€...ã€68}ã€å›³2ï¼ˆaï¼‰ã«ãƒ—ãƒ­ãƒƒãƒˆã•ã‚Œã¦ã„ã¾ã™ã€‚

- We use this method that relies on our implementation. Each landmark point ğ‘ ğ‘– is symmetric to another point ğ‘ ğ‘–ó¸€  with respect to the central axis of the face such as ğ‘ 22 and ğ‘ 23 , ğ‘ 49 , and ğ‘ 55 . The points located at the central axis are symmetric to themselves such as ğ‘ 28 and ğ‘ 31.

- To evaluate the rotation between the input and the reference face, the central axis of the input face should be extracted previously. According to the basic definition,


### 3.3.FaceWarping.

- Top reserve the shape of the swapped face, we warp the reference image to fit the aligned input face before face replacement. The warping is implemented based on the alignment of facial landmarks. We pick 18 out of the 68 facial landmarks and denote them with Î¦ğ‘Ÿ ={1,2,...,17,34} (see Figure 3(a)), which are considered to have a significant impact on facial shape.
    - äº¤æ›ã•ã‚ŒãŸé¡”ã®å½¢çŠ¶ã‚’ç¢ºä¿ã—ã€é¡”ã‚’äº¤æ›ã™ã‚‹å‰ã«å‚ç…§ç”»åƒã‚’ãƒ¯ãƒ¼ãƒ—ã—ã¦æ•´åˆ—ã—ãŸå…¥åŠ›é¡”ã«åˆã‚ã›ã¾ã™ã€‚ ãƒ¯ãƒ¼ãƒ”ãƒ³ã‚°ã¯ã€é¡”ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®é…ç½®ã«åŸºã¥ã„ã¦å®Ÿè£…ã•ã‚Œã¾ã™ã€‚ 68ã®é¡”ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‹ã‚‰18ã‚’é¸ã³ã€ãã‚Œã‚‰ã‚’Î¦ğ‘Ÿ= {1,2ã€...ã€17,34}ã§ç¤ºã—ã¾ã™ï¼ˆå›³3ï¼ˆaï¼‰ã‚’å‚ç…§ï¼‰ã€‚ã“ã‚Œã‚‰ã¯é¡”ã®å½¢ã«å¤§ããªå½±éŸ¿ãŒã‚ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚

- The landmarks of the reference face are denoted with ğ‘Ÿğ‘–,ğ‘– âˆˆ Î¦r. The new locations ğ‘Ÿwğ‘– of most of the landmarks (except ğ‘Ÿ1,ğ‘Ÿ17, and ğ‘Ÿ34) after the image warping should perfectly aligned to the input face, so we have

- Figure 3(b) illustrates the original landmarks (red points) and their new locations (green points). To realize the image warping, the reference image ğ¼ref is firstly decomposed into many triangle pieces based on the landmarks. The triangulation is required to minimize the change of the image background because we generally hope to preserve some parts in the background such as hair, body, and dress (that is why we do not move ğ‘Ÿ1 , ğ‘Ÿ17 , and ğ‘Ÿ34 ). The final layout of triangulation is designed as shown in Figure 3(a). Then the image warping can be realized by applying the specific affine transformation to the corresponding triangle pieces.
    - å›³3ï¼ˆbï¼‰ã¯ã€å…ƒã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ï¼ˆèµ¤ã„ç‚¹ï¼‰ã¨ãã®æ–°ã—ã„ä½ç½®ï¼ˆç·‘ã®ç‚¹ï¼‰ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ ç”»åƒã®ã‚†ãŒã¿ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã€å‚ç…§ç”»åƒğ¼refã¯æœ€åˆã«ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã«åŸºã¥ã„ã¦å¤šãã®ä¸‰è§’å½¢ã®æ–­ç‰‡ã«åˆ†è§£ã•ã‚Œã¾ã™ã€‚ ä¸€èˆ¬ã«ã€é«ªã®æ¯›ã€ä½“ã€ãƒ‰ãƒ¬ã‚¹ãªã©ã®èƒŒæ™¯ã®ä¸€éƒ¨ã‚’ä¿æŒã—ãŸã„ã®ã§ã€ç”»åƒã®èƒŒæ™¯ã®å¤‰åŒ–ã‚’æœ€å°é™ã«æŠ‘ãˆã‚‹ãŸã‚ã«ä¸‰è§’æ¸¬é‡ [triangulation] ãŒå¿…è¦ã§ã™ï¼ˆğ‘Ÿ1ã€ğ‘Ÿ17ã€ãŠã‚ˆã³move34ã‚’å‹•ã‹ã•ãªã„ç†ç”±ã§ã™ï¼‰ã€‚ ä¸‰è§’å½¢åˆ†å‰²ã®æœ€çµ‚ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã¯ã€å›³3ï¼ˆaï¼‰ã«ç¤ºã™ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ã€‚ æ¬¡ã«ã€å¯¾å¿œã™ã‚‹ä¸‰è§’å½¢ã®éƒ¨åˆ†ã«ç‰¹å®šã®ã‚¢ãƒ•ã‚£ãƒ³å¤‰æ›ã‚’é©ç”¨ã™ã‚‹ã“ã¨ã«ã‚ˆã‚Šã€ç”»åƒã®ãƒ¯ãƒ¼ãƒ”ãƒ³ã‚°ã‚’å®Ÿç¾ã§ãã¾ã™ã€‚

---

- xxx

### 3.4. Face Replacement.

- According to the pipeline of the proposed algorithm, we need to extract the input face-ROI ğ‘…ain and the reference face-ROI ğ‘…wref from the aligned input image ğ¼a and the warped reference image ğ¼w, respectively. A good in ref face-ROI should include as many facial features as possible while excluding background and distractors. However, most of traditional face swapping algorithms [2, 16] use a convex hull of the facial landmarks as the face-ROI which could cover some distracting areas like hair, hat, forehead, and neck. Therefore, in our model, a higher-precision face parsing algorithm based on deep learning [17] is introduced to extract a more accurate face-ROI. Different from the multiclass parsing network in paper [17], we use only two class labels, face and nonface, to train the parsing neural network based on the Helen dataset [18] which contains 2330 face images with pixel-level ground truth. Because our method requires face parsing rather than skin segmentation, so a contour detector is used. We initialize the encoder with pretrained VGG-16 net and the decoder with random values. During training, we fix the encoder parameters and only optimize the decoder parameters. The architecture of the network is shown in Figure 4. We set the learning rate to 0.0001 and train the network with 30 epochs with all the training images being processed each epoch. Then the face-ROIs can be generated by the retrained face parsing network.
    - ææ¡ˆã•ã‚ŒãŸã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«ã‚ˆã‚‹ã¨ã€ä½ç½®åˆã‚ã›ã•ã‚ŒãŸå…¥åŠ›ç”»åƒğ¼aã¨ãƒ¯ãƒ¼ãƒ—ã•ã‚ŒãŸå‚ç…§ç”»åƒfacewã‹ã‚‰ãã‚Œãã‚Œå…¥åŠ›é¢ROIğ‘…ainã¨åŸºæº–é¡”ROIğ‘…wrefã‚’æŠ½å‡ºã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ ref in ref-ROIã«ã¯ã€èƒŒæ™¯ã¨ãƒ‡ã‚£ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ã‚’é™¤å¤–ã—ãªãŒã‚‰ã€ã§ãã‚‹ã ã‘å¤šãã®é¡”ã®ç‰¹å¾´ã‚’å«ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ãŸã ã—ã€å¾“æ¥ã®é¡”äº¤æ›ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ã»ã¨ã‚“ã©[2ã€16]ã¯ã€é¡”ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®å‡¸åŒ…ã‚’é¡”ROIã¨ã—ã¦ä½¿ç”¨ã—ã€é«ªã€å¸½å­ã€é¡ã€é¦–ãªã©ã®æ°—ã‚’æ•£ã‚‰ã™é ˜åŸŸã‚’ã‚«ãƒãƒ¼ã§ãã¾ã™ã€‚
    - ãã®ãŸã‚ã€ã“ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯ã€ã‚ˆã‚Šæ­£ç¢ºãªé¡”ROIã‚’æŠ½å‡ºã™ã‚‹ãŸã‚ã«ã€ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°[17]ã«åŸºã¥ãé«˜ç²¾åº¦ã®é¡”è§£æã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒå°å…¥ã•ã‚Œã¦ã„ã¾ã™ã€‚è«–æ–‡[17]ã®ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹è§£æãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¨ã¯ç•°ãªã‚Šã€ãƒ”ã‚¯ã‚»ãƒ«ãƒ¬ãƒ™ãƒ«ã®ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ãƒˆã‚¥ãƒ«ãƒ¼ã‚¹ã‚’æŒã¤2330ã®é¡”ç”»åƒã‚’å«ã‚€Helenãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ[18]ã«åŸºã¥ã„ã¦è§£æãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ãŸã‚ã«ã€é¡”ã¨éé¡”ã®2ã¤ã®ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ã®ã¿ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ã“ã®æ–¹æ³•ã§ã¯ã€è‚Œã®ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯ãªãé¡”ã®è§£æãŒå¿…è¦ãªãŸã‚ã€è¼ªéƒ­æ¤œå‡ºå™¨ãŒä½¿ç”¨ã•ã‚Œã¾ã™ã€‚äº‹å‰å­¦ç¿’æ¸ˆã¿ã®VGG-16ãƒãƒƒãƒˆã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’åˆæœŸåŒ–ã—ã€ãƒ©ãƒ³ãƒ€ãƒ å€¤ã§ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä¿®æ­£ã—ã€ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿ã‚’æœ€é©åŒ–ã—ã¾ã™ã€‚ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’å›³4ã«ç¤ºã—ã¾ã™ã€‚å­¦ç¿’ç‡ã‚’0.0001ã«è¨­å®šã—ã€å„ã‚¨ãƒãƒƒã‚¯ã§å‡¦ç†ã•ã‚Œã‚‹ã™ã¹ã¦ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¤ãƒ¡ãƒ¼ã‚¸ã§30ã‚¨ãƒãƒƒã‚¯ã§ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã™ã€‚æ¬¡ã«ã€å†è¨“ç·´ã•ã‚ŒãŸé¡”è§£æãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«ã‚ˆã£ã¦é¡”ROIã‚’ç”Ÿæˆã§ãã¾ã™ã€‚


# â–  å®Ÿé¨“çµæœï¼ˆä¸»å¼µã®è¨¼æ˜ï¼‰ãƒ»è­°è«–ï¼ˆæ‰‹æ³•ã®è‰¯ã—æ‚ªã—ï¼‰ãƒ»ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆå®Ÿé¨“æ–¹æ³•ï¼‰

## 4. Experiment

- In the experimental part, we will verify the superiority of our model by comparing it with three popular face swapping algorithms [2, 7, 16] and analyze the experimental results from qualitative and quantitative aspects to explain the effectiveness of our method.
    - å®Ÿé¨“éƒ¨åˆ†ã§ã¯ã€3ã¤ã®ä¸€èˆ¬çš„ãªé¡”äº¤æ›ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ [2ã€7ã€16]ã¨æ¯”è¼ƒã™ã‚‹ã“ã¨ã§ãƒ¢ãƒ‡ãƒ«ã®å„ªä½æ€§ã‚’æ¤œè¨¼ã—ã€å®šæ€§çš„ãŠã‚ˆã³å®šé‡çš„å´é¢ã‹ã‚‰å®Ÿé¨“çµæœã‚’åˆ†æã—ã¦æ‰‹æ³•ã®æœ‰åŠ¹æ€§ã‚’èª¬æ˜ã—ã¾ã™ã€‚

---

- In the qualitative experiment, we use the photos of several public figures as input image and reference image, respectively, as shown in Figure 7 [7]. The five reference faces have different postures, genders, skin tones, face shapes, and hairstyles, while the input faces include a male and a female face. The corresponding visual results obtained by the competing algorithms and our model are shown in Figure 8, where the five reference faces are replaced with two input faces, respectively. Figures 8(a) and 8(b), respectively, give the face swapping results for the male input face and female input face, where each column corresponds to a reference face and each row corresponds to a face swapping algorithm. On the whole, the face swapping results of the learning-based algorithm [7] (denoted as L1) is more natural and realistic and has a good adaptability to the different perspectives, hairstyles, and skin colors. However, as mentioned above, this method is only valid for the identities with a large number of training images, and each face identity corresponds to a generative neural network. In other words, this method cannot be applied to untrained new face images, which seriously restricts the application of this method. Our model promises the real sense of the face swapping result as well, and it is only slightly worse than the L-model in dealing with the perspective variance. In addition, this paper introduces the steps of the precise face parsing and the adaptive color correction, so it can effectively solve the problem of skin color difference and hair occlusion. While the other two replacement-based algorithms (denoted as R1 [16] and R2 [2]) have only adopted relatively simple algorithm flow, it is impossible to remove the boundary effects completely.
    - å®šæ€§å®Ÿé¨“ã§ã¯ã€å›³7 [7]ã«ç¤ºã™ã‚ˆã†ã«ã€å…¥åŠ›ç”»åƒã¨å‚ç…§ç”»åƒã¨ã—ã¦ã€ãã‚Œãã‚Œã„ãã¤ã‹ã®å…¬äººã®å†™çœŸã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ 5ã¤ã®å‚ç…§é¢ã«ã¯ã€ç•°ãªã‚‹å§¿å‹¢ã€æ€§åˆ¥ã€è‚Œã®è‰²ã€é¡”ã®å½¢ã€é«ªå‹ãŒã‚ã‚Šã¾ã™ãŒã€å…¥åŠ›é¢ã«ã¯ç”·æ€§ã¨å¥³æ€§ã®é¡”ãŒå«ã¾ã‚Œã¾ã™ã€‚ç«¶åˆã™ã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¨ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦å¾—ã‚‰ã‚ŒãŸå¯¾å¿œã™ã‚‹è¦–è¦šçš„çµæœã‚’å›³8ã«ç¤ºã—ã¾ã™ã€‚5ã¤ã®å‚ç…§é¢ãŒãã‚Œãã‚Œ2ã¤ã®å…¥åŠ›é¢ã«ç½®ãæ›ãˆã‚‰ã‚Œã¦ã„ã¾ã™ã€‚å›³8ï¼ˆaï¼‰ã¨8ï¼ˆbï¼‰ã¯ã€ãã‚Œãã‚Œã€ç”·æ€§ã®å…¥åŠ›é¢ã¨å¥³æ€§ã®å…¥åŠ›é¢ã®é¡”äº¤æ›çµæœã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚å„åˆ—ã¯å‚ç…§é¢ã«å¯¾å¿œã—ã€å„è¡Œã¯é¡”äº¤æ›ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚å…¨ä½“ã¨ã—ã¦ã€å­¦ç¿’ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ [7]ï¼ˆL1ã¨è¡¨è¨˜ï¼‰ã®é¡”äº¤æ›çµæœã¯ã€ã‚ˆã‚Šè‡ªç„¶ã§ç¾å®Ÿçš„ã§ã‚ã‚Šã€ã•ã¾ã–ã¾ãªè¦–ç‚¹ã€é«ªå‹ã€è‚Œã®è‰²ã«ã‚ˆãé©å¿œã—ã¾ã™ã€‚ãŸã ã—ã€å‰è¿°ã®ã‚ˆã†ã«ã€ã“ã®æ–¹æ³•ã¯å¤šæ•°ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”»åƒã‚’æŒã¤ã‚¢ã‚¤ãƒ‡ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã«å¯¾ã—ã¦ã®ã¿æœ‰åŠ¹ã§ã‚ã‚Šã€å„é¡”ã®ã‚¢ã‚¤ãƒ‡ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã¯ç”Ÿæˆãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«å¯¾å¿œã—ã¾ã™ã€‚è¨€ã„æ›ãˆã‚Œã°ã€ã“ã®æ–¹æ³•ã¯ã€è¨“ç·´ã•ã‚Œã¦ã„ãªã„æ–°ã—ã„é¡”ã®ç”»åƒã«ã¯é©ç”¨ã§ããšã€ã“ã®æ–¹æ³•ã®é©ç”¨ãŒå¤§å¹…ã«åˆ¶é™ã•ã‚Œã¾ã™ã€‚ç§ãŸã¡ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€é¡”äº¤æ›çµæœã®æœ¬å½“ã®æ„å‘³ã‚‚ç´„æŸã—ã¾ã™ã€‚ã¾ãŸã€è¦–ç‚¹ã®åˆ†æ•£ã‚’å‡¦ç†ã™ã‚‹éš›ã«ã€Lãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚ãšã‹ã«æ‚ªã„ã ã‘ã§ã™ã€‚ã•ã‚‰ã«ã€ã“ã®ãƒ›ãƒ¯ã‚¤ãƒˆãƒšãƒ¼ãƒ‘ãƒ¼ã§ã¯ã€æ­£ç¢ºãªé¡”ã®è§£æã¨é©å¿œè‰²è£œæ­£ã®æ‰‹é †ã‚’ç´¹ä»‹ã—ã¦ã„ã‚‹ãŸã‚ã€è‚Œã®è‰²ã®é•ã„ã¨é«ªã®é–‰å¡ã®å•é¡Œã‚’åŠ¹æœçš„ã«è§£æ±ºã§ãã¾ã™ã€‚ä»–ã®2ã¤ã®ç½®æ›ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆR1 [16]ãŠã‚ˆã³R2 [2]ã¨è¡¨ç¤ºï¼‰ã¯æ¯”è¼ƒçš„å˜ç´”ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒ•ãƒ­ãƒ¼ã®ã¿ã‚’æ¡ç”¨ã—ã¦ã„ã¾ã™ãŒã€å¢ƒç•ŒåŠ¹æœã‚’å®Œå…¨ã«é™¤å»ã™ã‚‹ã“ã¨ã¯ä¸å¯èƒ½ã§ã™ã€‚

---

- Many specific applications require that the facial features and face shape should remain as they should be in the face swapping, so a quantitative experiment is designed to verify the similarity between the face swapping result and the input face. Table 1 gives the similarity measures between the input face and the swapping results shown in Figure 8, which are obtained by a CNN-based model [21]. The higher scores in Table 1 represent the higher similarity. According to Table 1, our model is obviously better than the L-model and the R2- model while slightly lower than the R1-model in some cases. This is because that the L-model produces the composite face with a slight modification of the facial features to ensure the reality of the swapping results. The R2-model does not involve the color correction step and thus has a lower score. The R1-model has the highest similarity because it retains the complete face region at the expense of partially reducing the reality of the boundaries between forehead and hair. In contrast, our model preserves almost all of the facial features of the original input face while guaranteeing the reality of the swapped face, which leads to a better balance between similarity and realism.

# â–  é–¢é€£ç ”ç©¶ï¼ˆä»–ã®æ‰‹æ³•ã¨ã®é•ã„ï¼‰

## x. Related Work


- xxx

---

- In the model-based approach [3], a two-dimensional or three-dimensional parametric feature model is established to represent human face, and the parameters and features are well-adjusted to the input image. Then the face reconstruction is performed on the reference image based on the result of adjusting the model parameters.
    - **ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ[3]ã§ã¯ã€2æ¬¡å…ƒã¾ãŸã¯3æ¬¡å…ƒã®ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯ãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¢ãƒ‡ãƒ«ãŒç¢ºç«‹ã•ã‚Œã€äººé–“ã®é¡”ãŒè¡¨ç¾ã•ã‚Œã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ãƒ•ã‚£ãƒ¼ãƒãƒ£ãŒå…¥åŠ›ç”»åƒã«åˆã‚ã›ã¦èª¿æ•´ã•ã‚Œã¾ã™ã€‚ æ¬¡ã«ã€ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª¿æ•´çµæœã«åŸºã¥ã„ã¦ã€å‚ç…§ç”»åƒã§é¡”ã®å†æ§‹æˆãŒå®Ÿè¡Œã•ã‚Œã¾ã™ã€‚**

- An early work presented by Blanz and Volker et al [4] used a 3D model to estimate the face shape and posture, which improved the shortcoming of the unsatisfied performance of the synthesis due to the illumination and the perspective. However, the algorithm requires a 3D input model and a manual initialization to get a better result, which undoubtedly has a stricter requirement for data acquisition. Wang et al [5] proposed an algorithm based on active apparent model (AAM). By using the well trained AAM, the face swapping is realized in two steps: model fitting and component composite. But this method needs to specify the face-ROI manually and a certain number of face images for model training. Lin et al [6] presented a method of constructing a 3D model based on the frontal face image to deal with the different perspectives of reference image and input image. But the reconstructed model does not reflect the characteristics of the original face precisely and takes too much time to compute.
    - Blanzã¨Volker et al [4]ãŒç™ºè¡¨ã—ãŸåˆæœŸã®ç ”ç©¶ã§ã¯ã€3Dãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦é¡”ã®å½¢çŠ¶ã¨å§¿å‹¢ã‚’æ¨å®šã—ã¾ã—ãŸã€‚ãŸã ã—ã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ã¯ã€ã‚ˆã‚Šè‰¯ã„çµæœã‚’å¾—ã‚‹ãŸã‚ã«3Då…¥åŠ›ãƒ¢ãƒ‡ãƒ«ã¨æ‰‹å‹•ã®åˆæœŸåŒ–ãŒå¿…è¦ã§ã‚ã‚Šã€é–“é•ã„ãªããƒ‡ãƒ¼ã‚¿å–å¾—ã®è¦ä»¶ãŒå³ã—ããªã‚Šã¾ã™ã€‚ Wang et al [5]ã¯ã€ã‚¢ã‚¯ãƒ†ã‚£ãƒ–è¦‹ã‹ã‘ãƒ¢ãƒ‡ãƒ«ï¼ˆAAMï¼‰ã«åŸºã¥ãã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ææ¡ˆã—ã¾ã—ãŸã€‚ã‚ˆãè¨“ç·´ã•ã‚ŒãŸAAMã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã«ã‚ˆã‚Šã€é¡”ã®äº¤æ›ã¯2ã¤ã®ã‚¹ãƒ†ãƒƒãƒ—ã§å®Ÿç¾ã•ã‚Œã¾ã™ï¼šãƒ¢ãƒ‡ãƒ«ã®é©åˆã¨ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®è¤‡åˆã€‚ãŸã ã—ã€ã“ã®æ–¹æ³•ã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã«é¡”ã®ROIã¨ç‰¹å®šã®æ•°ã®é¡”ç”»åƒã‚’æ‰‹å‹•ã§æŒ‡å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ Linã‚‰[6]ã¯ã€æ­£é¢ç”»åƒã«åŸºã¥ã„ã¦3Dãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã€å‚ç…§ç”»åƒã¨å…¥åŠ›ç”»åƒã®ã•ã¾ã–ã¾ãªè¦–ç‚¹ã‚’å‡¦ç†ã™ã‚‹æ–¹æ³•ã‚’æç¤ºã—ã¾ã—ãŸã€‚ã—ã‹ã—ã€å†æ§‹ç¯‰ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯å…ƒã®é¡”ã®ç‰¹å¾´ã‚’æ­£ç¢ºã«åæ˜ ã›ãšã€è¨ˆç®—ã«æ™‚é–“ãŒã‹ã‹ã‚Šã™ãã¾ã™ã€‚

---

- Above all, the replacement-based approach is simple and fast but sensitive to the variation in posture and perspective. The model-based method can effectively solve the perspective problem; however, it usually needs to collect three-dimensional face data, and robustness is not something to be satisfied. The learning-based approach can produce quite real and natural synthetic face image, while usually requiring a large number of training data and having more restrictions on the input and reference faces. Based on the comprehensive consideration of the characteristics of the above three methods, a face swapping algorithm supported by the facial landmark alignment is proposed under the replacement-based framework.
    - ã¨ã‚Šã‚ã‘ã€ç½®æ›ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã‚·ãƒ³ãƒ—ãƒ«ã‹ã¤é«˜é€Ÿã§ã™ãŒã€å§¿å‹¢ã‚„è¦–ç‚¹ [perspective] ã®å¤‰åŒ–ã«æ•æ„Ÿã§ã™ã€‚
    - **ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ã®æ–¹æ³•ã¯ã€è¦–ç‚¹ã®å•é¡Œã‚’åŠ¹æœçš„ã«è§£æ±ºã§ãã¾ã™ã€‚** ãŸã ã—ã€é€šå¸¸ã¯3æ¬¡å…ƒã®é¡”ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã€å …ç‰¢æ€§ã¯æº€è¶³ã™ã¹ãã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
    - å­¦ç¿’ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯ã€éå¸¸ã«ãƒªã‚¢ãƒ«ã§è‡ªç„¶ãªåˆæˆé¡”ç”»åƒã‚’ç”Ÿæˆã§ãã¾ã™ãŒã€é€šå¸¸ã€å¤§é‡ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã‚ã‚Šã€å…¥åŠ›é¡”ã¨å‚ç…§é¡”ã«ã‚ˆã‚Šå¤šãã®åˆ¶é™ãŒã‚ã‚Šã¾ã™ã€‚
    - ä¸Šè¨˜ã®3ã¤ã®æ–¹æ³•ã®ç‰¹æ€§ã®åŒ…æ‹¬çš„ãªè€ƒæ…®ã«åŸºã¥ã„ã¦ã€é¡”ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯èª¿æ•´ã«ã‚ˆã£ã¦ã‚µãƒãƒ¼ãƒˆã•ã‚Œã‚‹é¡”äº¤æ›ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒã€ç½®æ›ãƒ™ãƒ¼ã‚¹ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®ä¸‹ã§ææ¡ˆã•ã‚Œã¦ã„ã¾ã™ã€‚

- In addition, other widely used algorithms have been applied in our methods to achieve better results, such as facial landmark detection [9, 10], facial region segmentation [11, 12], and face warping [13]. And we will detail how these algorithms are applied in the method section.
    - ã•ã‚‰ã«ã€é¡”ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æ¤œå‡º[9ã€10]ã€é¡”é ˜åŸŸã®ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³[11ã€12]ã€é¡”ã®ãƒ¯ãƒ¼ãƒ”ãƒ³ã‚°[13]ãªã©ã€ä»–ã®åºƒãä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒã‚ˆã‚Šè‰¯ã„çµæœã‚’å¾—ã‚‹ãŸã‚ã«ç§ãŸã¡ã®æ–¹æ³•ã«é©ç”¨ã•ã‚Œã¾ã—ãŸã€‚ ãã—ã¦ã€ã“ã‚Œã‚‰ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒã©ã®ã‚ˆã†ã«é©ç”¨ã•ã‚Œã‚‹ã‹ã«ã¤ã„ã¦ã€ãƒ¡ã‚½ãƒƒãƒ‰ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§è©³ã—ãèª¬æ˜ã—ã¾ã™ã€‚

