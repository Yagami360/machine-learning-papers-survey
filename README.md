# MachineLearning-Papers_Survey
機械学習関連の論文 Survey 用レポジトリです。<br>
論文まとめ記事は、[Issues](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues) に記載しています。進捗は、[Projects ページ](https://github.com/Yagami360/MachineLearning-Papers_Survey/projects/1) で管理しています。

## ■ 構成

### ◎ 基礎系（基礎モデル）

- Deep Neural Network
    - [[ResNet] Deep Residual Learning for Image Recognition](https://github.com/Yagami360/My_NoteBook/blob/master/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6_%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92_NN_Note.md#ResNet%EF%BC%88%E6%AE%8B%E5%B7%AE%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF%EF%BC%89)
    - [[Neural-ODE] Neural Ordinary Differential Equations](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/21)
    - [Augmented Neural ODEs](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/37)
- CNN
    - [Spatial Transformer Networks](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/48)
- GNN
    - [Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering](https://github.com/Yagami360/My_NoteBook/blob/master/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6_%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92_NN_Note.md#Convolutional_Neural_Networks_on_Graphs_with_Fast_Localized_Spectral_Filtering)
    - [Semi-Supervised Classification with Graph Convolutional Networks](https://github.com/Yagami360/My_NoteBook/blob/master/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6_%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92_NN_Note.md#Semi-Supervised_Classification_with_Graph_Convolutional_Networks)
    - [[R-GCN] Relational Graph Convolutional Network](https://github.com/Yagami360/My_NoteBook/blob/master/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6_%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92_NN_Note.md#R-GCN%EF%BC%88%E3%82%B0%E3%83%A9%E3%83%95%E3%83%95%E3%83%BC%E3%83%AA%E3%82%A8%E5%A4%89%E6%8F%9B%E3%82%92%E7%94%A8%E3%81%84%E3%81%AA%E3%81%84%E3%82%B0%E3%83%A9%E3%83%95%E7%95%B3%E3%81%BF%E8%BE%BC%E3%81%BF%EF%BC%89)
- VAE
    - [[VAE] Auto-Encoding Variational Bayes](https://github.com/Yagami360/My_NoteBook/blob/master/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6_%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92_%E7%94%9F%E6%88%90%E3%83%A2%E3%83%87%E3%83%AB.md#VAE)
    - [[VQ-VAE] Neural Discrete Representation Learning](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/23)
    - [β-VAE: LEARNING BASIC VISUAL CONCEPTS WITH A CONSTRAINED VARIATIONAL FRAMEWORK](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/27)
- GANs
    - [[GAN] Generative Adversarial Networks](https://github.com/Yagami360/My_NoteBook/blob/master/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6_%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92_%E7%94%9F%E6%88%90%E3%83%A2%E3%83%87%E3%83%AB.md#GAN)
    - [[DCGAN] Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://github.com/Yagami360/My_NoteBook/blob/master/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6_%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92_%E7%94%9F%E6%88%90%E3%83%A2%E3%83%87%E3%83%AB.md#DCGAN)
    - [[cGAN] Conditional Generative Adversarial Nets](https://github.com/Yagami360/My_NoteBook/blob/master/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6_%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92_%E7%94%9F%E6%88%90%E3%83%A2%E3%83%87%E3%83%AB.md#ConditionalGAN%EF%BC%88cGAN%EF%BC%89)
    - [[WGAN] Wasserstein GAN](https://github.com/Yagami360/My_NoteBook/blob/master/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6_%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92_%E7%94%9F%E6%88%90%E3%83%A2%E3%83%87%E3%83%AB.md#WGAN)
    - [[WGAN-gp] improved Training of Wasserstein GANs](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/25)
    - [SAGAN [Self-Attention Generative Adversarial Networks]](https://github.com/Yagami360/My_NoteBook/blob/master/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6_%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92_%E7%94%9F%E6%88%90%E3%83%A2%E3%83%87%E3%83%AB.md#SAGAN)
    - [InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/26)
    - [[PGGAN] Progressive Growing of GANs for Improved Quality, Stability, and Variation](https://github.com/Yagami360/My_NoteBook/blob/master/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6_%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92_%E7%94%9F%E6%88%90%E3%83%A2%E3%83%87%E3%83%AB.md#ProgressiveGAN%EF%BC%88PGGAN%EF%BC%89)
    - [[StyleGAN] A Style-Based Generator Architecture for Generative Adversarial Networks](https://github.com/Yagami360/My_NoteBook/blob/master/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6_%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92_%E7%94%9F%E6%88%90%E3%83%A2%E3%83%87%E3%83%AB.md#StyleGAN)
    - [[StyleGAN2] Analyzing and Improving the Image Quality of StyleGAN](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/52)
    - [GAN-Tree: An Incrementally Learned Hierarchical Generative Framework for Multi-Modal Data Distributions](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/19)
    - [[RSGAN,RGAN,RaGAN] The relativistic discriminator: a key element missing from standard GAN](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/51)
- Flow-based generative model
    - [NICE: NON-LINEAR INDEPENDENT COMPONENTS ESTIMATION](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/10)
    - [Real NVP [Density estimation using Real NVP]](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/11)
    - [Glow [Generative Flow with Invertible 1×1 Convolutions]](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/13)
    - [i-ResNets [Invertible residual networks]](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/14)
    - [Residual Flows for Invertible Generative Modeling](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/15)
- Autoregressive Models
    - [[PixelRNN, PixelCNN] Pixel Recurrent Neural Networks](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/24)

- meta-learning, few-shot learning
    - [MAML:Model Agnostic Meta-Learning for Fast Adaption](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/39)
- Neural Processes
    - [Conditional Neural Processes](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/38)
    - [Neural Processes](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/44)

### ◎ アプリケーション系（CV）
- Image Classification
    - xxx
- Semantic Segmentation
    - [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://github.com/Yagami360/My_NoteBook/blob/master/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6_%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92_%E7%94%9F%E6%88%90%E3%83%A2%E3%83%87%E3%83%AB.md#UNet)
    - [[PSPNet] Pyramid Scene Parsing Network](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/69)
    - [Pyramid Attention Network for Semantic Segmentation](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/63)
    - [[DeepLab v3+] Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/68)
    - [Concurrent Spatial and Channel ‘Squeeze & Excitation’ in Fully Convolutional Networks](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/62)
    - [Hypercolumns for Object Segmentation and Fine-grained Localization](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/64)
    - [Tversky loss function for image segmentation using 3D fully convolutional deep networks](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/67)
    - [Boundary loss for highly unbalanced segmentation](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/77)
    - Human Parsing
        - [[JPPNet] Look into Person: Joint Body Parsing & Pose Estimation Network and A New Benchmark](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/70)
        - [[CE2P] Devil in the Details: Towards Accurate Single and Multiple Human Parsing](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/72)
        - [Graphonomy: Universal Human Parsing via Graph Transfer Learning](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/8)
        - [Hierarchical Human Parsing with Typed Part-Relation Reasoning](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/79)
        - [[CorrPM] Correlating Edge, Pose with Parsing](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/74)
- Object Detection
    - [Fast R-CNN](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/75)
    - [Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/76)
    - [Focal Loss for Dense Object Detection](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/66)
- Instance Segmentation
    - [Mask R-CNN](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/65)
    - Human Parsing
        - [Parsing R-CNN for Instance-Level Human Analysis](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/73)
- Pose Estimation
    - [DensePose: Dense Human Pose Estimation in the Wild](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/50)
- Image Registration / geometric matching
    - [Convolutional neural network architecture for geometric matching](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/36)
- image-to-image
    - [[pix2pix] Image-to-Image Translation with Conditional Adversarial Networks](https://github.com/Yagami360/My_NoteBook/blob/master/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6_%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92_%E7%94%9F%E6%88%90%E3%83%A2%E3%83%87%E3%83%AB.md#pix2pix)
    - [[pix2pix-HD] High-Resolution_Image_Synthesis_and_Semantic_Manipulation_with_Conditional_GANs](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/18)
    - [[CycleGAN] Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks](https://github.com/Yagami360/My_NoteBook/blob/master/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6_%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92_%E7%94%9F%E6%88%90%E3%83%A2%E3%83%87%E3%83%AB.md#CycleGAN)
    - [[StarGAN] StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation](https://github.com/Yagami360/My_NoteBook/blob/master/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6_%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92_%E7%94%9F%E6%88%90%E3%83%A2%E3%83%87%E3%83%AB.md#StarGAN)
    - [[SPADE] Semantic Image Synthesis with Spatially-Adaptive Normalization](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/7)
    - [[Neural Collage] Spatially Controllable Image Synthesis with Internal Representation Collaging](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/22)
    - [SinGAN: Learning a Generative Model from a Single Natural Image](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/40)  
    - [Recapture as You Want](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/78)
- Inpainting
    - [[Deepfillv2] Free-Form Image Inpainting with Gated Convolution](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/29)
    - [Pluralistic Image Completion](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/6)
    - [Boundless: Generative Adversarial Networks for Image Extension](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/28)
- Person Image Generation
    - [Pose Guided Person Image Generation](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/49)
    - [Disentangled Person Image Generation](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/41)
    - [[Soft-Gated Warping-GAN] Soft-Gated Warping-GAN for Pose-Guided Person Image Synthesis](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/35)
- 顔特化系（Face Swap, etc）
    - [[GANimation] GANimation: Anatomically-aware Facial Animation from a Single Image](https://github.com/Yagami360/My_NoteBook/blob/master/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6_%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92_%E7%94%9F%E6%88%90%E3%83%A2%E3%83%87%E3%83%AB.md#GANimation)
    - [On Face Segmentation, Face Swapping, and Face Perception](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/3)
    - [Face Swapping: Realistic Image Synthesis Based on Facial Landmarks Alignment](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/4)
- Virtual Try-On
    - [VITON: An Image-based Virtual Try-on Network](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/30)
    - [[CP-VTON] Toward Characteristic-Preserving Image-based Virtual Try-On Network](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/53)
    - [[MG-VTON] Towards_Multi-pose_Guided_Virtual_Try-on_Network](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/5)
    - [[WUTON] End-to-End Learning of Geometric Deformations of Feature Maps for Virtual Try-On](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/12)
    - [Generating High-Resolution Fashion Model Images Wearing Custom Outfits](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/16)
    - [Poly-GAN: Multi-Conditioned GAN for Fashion Synthesis](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/17)
    - [Virtually Trying on New Clothing with Arbitrary Poses](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/31)
    - [FW-GAN: Flow-navigated Warping GAN for Video Virtual Try-on](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/42)
    - [Robust Cloth Warping via Multi-Scale Patch Adversarial Loss for Virtual Try-On Framework](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/45)
    - [ClothFlow: A Flow-Based Model for Clothed Person Generation](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/46)
    - [SieveNet: A Unified Framework for Robust Image-Based Virtual Try-On](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/54)
    - [GarmentGAN: Photo-realistic Adversarial Fashion Transfer](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/56)
    - [[ACGPN] Towards Photo-Realistic Virtual Try-On by Adaptively Generating↔Preserving Image Content](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/55)
    - [Toward Accurate and Realistic Virtual Try-on Through Shape Matching and Multiple Warps](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/57)
    - [DEEP LEARNING APPROACHES FOR ATTRIBUTE MANIPULATION AND TEXT-TO-IMAGE SYNTHESIS / Chapter4 : Attribute Manipulation Generative Adversarial Networks for Image-to-Image Translation](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/58)
    - [LGVTON: A Landmark Guided Approach to Virtual Try-On](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/59)
    - [FashionOn: Semantic-guided Image-based Virtual Try-on with Detailed Human and Clothing Information](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/61)
    - [[Outfit-VITON] Image Based Virtual Try-On Network From Unpaired Data](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/71)
    - [Do Not Mask What You Do Not Need to Mask: a Parser-Free Virtual Try-On](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/80)
    - [CP-VTON+: Clothing Shape and Texture Preserving Image-Based Virtual Try-On](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/82)
    - [3D Reconstruction of Clothes using a Human Body Model and its Application to Image-based Virtual Try-On](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/88)
- recommendation
    - [ViBE: Dressing for Diverse Body Shapes](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/60)
- text-to-image
    - [[StackGAN] Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Network](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/9)
- Optical Flow
    - [FlowNet: Learning Optical Flow with Convolutional Networks](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/43)
    - [View Synthesis by Appearance Flow](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/47)
- 3D Reconstruction
    - param-to-3D / parametric 3D models
        - [SMPL: A skinned multi-person linear model ](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/86)
        - [[CAPE] Learning to Dress 3D People in Generative Clothing](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/93)
        - [TailorNet: Predicting Clothing in 3D as a Function of Human Pose, Shape and Garment Style](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/91)
        - [SIZER: A Dataset and Model for Parsing 3D Clothing and Learning Size Sensitive 3D Clothing](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/84)
    - image-to-3D / image-based 3D Reconstruction 
        - none-parametric 3D models
            - [Mesh R-CNN](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/83)
             - [Occupancy Networks: Learning 3D Reconstruction in Function Space](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/90)
            - [PIFuHD: Multi-Level Pixel-Aligned Implicit Function for High-Resolution 3D Human Digitization](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/94)
            - [NormalGAN: Learning Detailed 3D Human from a Single RGB-D Image](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/95)
            - [3D Virtual Garment Modeling from RGB Images](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/81)
        - parametric 3D models
            - [Multi-Garment Net: Learning to Dress 3D People from Images](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/87)
            - [Deep Fashion3D: A Dataset and Benchmark for 3D Garment Reconstruction from Single Images](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/89)
            - [BCNet: Learning Body and Cloth Shape from A Single Image](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/92)
    - video-to-3D
        - [TexMesh: Reconstructing Detailed Human Texture and Geometry from RGB-D Video](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/96)
    - Texture Mapping
        - [Learning to Transfer Texture from Clothing Images to 3D Humans](https://github.com/Yagami360/MachineLearning-Papers_Survey/issues/85)
- Others
    - xxx

### ◎ 理論系

- xxx

## ■ 機械学習系の論文調査や論文の読み方

- 論文調査
    - その論文の発展版を探すには、Google Scholer でその論文の被引用論文を探すのが手っ取り早い。
    - 基本的には、その論文の被引用数が多いものが注目の論文。但し最新の論文は当然被引用数は少なくなる。
    - 基本的には、最新の論文ほど優れた実験結果を出しているので、Google Scholer で出来るだけ公開日時の最新のものを探す。
    - 論文の公式実装がないものは、自前実装の再現コストが高いので、公式実装があるものを優先的に探す。
    - 論文の公式実装の有無は、papers with code で確認できる。

- 論文の読み方
    - 基本的に、「Abstract」→「Introduction」→「Conclusion」→「何をしたかの詳細」→「Experiments」→「Related Work」項目の順に読むのが効率的。Related Work は最悪飛ばしても良い。
    - Abstract や Introduction 内の "In this paper ...", "In this work ..." という文面や、Introduction の最後にある "the contributions of this paper ... as follows." という文面には注目。
    - その論文の未解決課題や問題点は、論文中の Future work や Conculution に述べられていることが多い。或いは、その論文を引用している論文の Related Work に述べられていることが多い。


## ■ 論文要約フォーマット（要約バージョン）

```
layout: post

title:  "論文タイトル"

date:   YYYY-MM-DD

categories: CV NLP Others

## 1. どんなもの？

## 2. 先行研究と比べてどこがすごいの？

## 3. 技術や手法の"キモ"はどこにある？

![Figure 1]({{ site.baseurl }}/assets/img/(cv, nlp, others)/(title)/figure1.png)

## 4. どうやって有効だと検証した？

## 5. 議論はあるか？

## 6. 次に読むべき論文はあるか？

### 論文情報・リンク

* [著者，"タイトル，" ジャーナル名，voluem，no.，ページ，年](論文リンク)

```
- [例）先端技術とメディア表現1 #FTMA15](http://www.slideshare.net/Ochyai/1-ftma15) from [Yoichi Ochiai](http://www.slideshare.net/Ochyai)

![](https://raw.githubusercontent.com/shunk031/paper-survey/master/assets/img/FTMA15-1-page-65.png)


## ■ 参考サイト

### ◎ 論文サイト
- [arXiv](https://arxiv.org/)
- [Google Scholer](https://scholar.google.co.jp/schhp?hl=ja&as_sdt=0,5)

### ◎ 便利サイト
- [DeepL](https://www.deepl.com/translator)
- [papers with code](https://paperswithcode.com/)
    - 論文実装の有無を確認できる。    
- [Hyper Collocation](https://hypcol.marutank.net/ja/)
- [arXiv Vanity](https://www.arxiv-vanity.com/)

### ◎ その他参考サイト
- [arXivTimes](https://github.com/arXivTimes/arXivTimes)
- [ymym3412/acl-papers](https://github.com/ymym3412/acl-papers)
- [shunk031/paper-survey](https://github.com/shunk031/paper-survey)
