# â–  è«–æ–‡
- è«–æ–‡ã‚¿ã‚¤ãƒˆãƒ«ï¼š"xxx"
- è«–æ–‡ãƒªãƒ³ã‚¯ï¼š
- è«–æ–‡æŠ•ç¨¿æ—¥ä»˜ï¼š
- è‘—è€…ï¼ˆçµ„ç¹”ï¼‰ï¼š
- categoriesï¼š

# â–  æ¦‚è¦ï¼ˆä½•ã‚’ã—ãŸã‹ï¼Ÿï¼‰

## Abstract

- Providing vibrotactile feedback that corresponds to the state of the virtual texture surfaces allows users to sense haptic properties of them. However, hand-tuning such vibrotactile stimuli for every state of the texture takes much time.
    - ä»®æƒ³ãƒ†ã‚¯ã‚¹ãƒãƒ£è¡¨é¢ã®çŠ¶æ…‹ã«å¯¾å¿œã™ã‚‹æŒ¯å‹•è§¦è¦šãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ã™ã‚‹ã“ã¨ã¯ã€ãƒ¦ãƒ¼ã‚¶ãŒãã‚Œã‚‰ã®è§¦è¦šç‰¹æ€§ã‚’æ„ŸçŸ¥ã™ã‚‹ã“ã¨ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚ã—ã‹ã—ãªãŒã‚‰ã€ãƒ†ã‚¯ã‚¹ãƒãƒ£ã®ã‚ã‚‰ã‚†ã‚‹çŠ¶æ…‹ã«å¯¾ã—ã¦ãã®ã‚ˆã†ãªæŒ¯å‹•è§¦è¦šåˆºæ¿€ã‚’æ‰‹å‹•ã§èª¿æ•´ã™ã‚‹ã“ã¨ã¯å¤šãã®æ™‚é–“ãŒã‹ã‹ã‚‹ã€‚

- Therefore, we propose a new approach to create models that realize the automatic vibrotactile generation from texture images or attributes. In this paper, we make the first attempt to generate the vibrotactile stimuli leveraging the power of deep generative adversarial training. Specifically, we use conditional generative adversarial networks (GANs) to achieve generation of vibration during moving a pen on the surface.
    - ãã“ã§ã€ãƒ†ã‚¯ã‚¹ãƒãƒ£ç”»åƒã‚„å±æ€§ã‹ã‚‰è‡ªå‹•æŒ¯å‹•è§¦è¦šç”Ÿæˆã‚’å®Ÿç¾ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã™ã‚‹ãŸã‚ã®æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã¾ã™ã€‚æœ¬ç¨¿ã§ã¯ã€æ·±ã„ç”Ÿæˆçš„ãªæ•µå¯¾çš„è¨“ç·´ã®åŠ›ã‚’åˆ©ç”¨ã—ã¦æŒ¯å‹•è§¦è¦šåˆºæ¿€ã‚’ç”Ÿæˆã™ã‚‹æœ€åˆã®è©¦ã¿ã‚’è¡Œã„ã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€æˆ‘ã€…ã¯ã€è¡¨é¢ä¸Šã§ãƒšãƒ³ã‚’å‹•ã‹ã—ã¦ã„ã‚‹é–“ã«æŒ¯å‹•ã®ç™ºç”Ÿã‚’é”æˆã™ã‚‹ãŸã‚ã«æ¡ä»¶ä»˜ãç”Ÿæˆå‹æ•µå¯¾çš„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆï¼§ï¼¡ï¼®ï¼‰ã‚’ä½¿ç”¨ã™ã‚‹ã€‚

- The preliminary user study showed that users could not discriminate generated signals and genuine ones and users felt realism for generated signals. Thus our model could provide the appropriate vibration according to the texture images or the attributes of them. Our approach is applicable to any case where the users touch the various surfaces in a predefined way.
    - äºˆå‚™çš„ãªãƒ¦ãƒ¼ã‚¶èª¿æŸ»ã¯ã€ãƒ¦ãƒ¼ã‚¶ãŒç”Ÿæˆã•ã‚ŒãŸä¿¡å·ã¨æœ¬ç‰©ã®ä¿¡å·ã¨ã‚’åŒºåˆ¥ã™ã‚‹ã“ã¨ãŒã§ããšã€ãƒ¦ãƒ¼ã‚¶ãŒç”Ÿæˆã•ã‚ŒãŸä¿¡å·ã«å¯¾ã—ã¦ãƒªã‚¢ãƒªã‚ºãƒ ã‚’æ„Ÿã˜ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã—ãŸãŒã£ã¦ã€æˆ‘ã€…ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒ†ã‚¯ã‚¹ãƒãƒ£ç”»åƒã¾ãŸã¯ãã‚Œã‚‰ã®å±æ€§ã«å¾“ã£ã¦é©åˆ‡ãªæŒ¯å‹•ã‚’æä¾›ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ç§ãŸã¡ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒäº‹å‰å®šç¾©ã•ã‚ŒãŸæ–¹æ³•ã§ã•ã¾ã–ã¾ãªã‚µãƒ¼ãƒ•ã‚§ã‚¹ã«è§¦ã‚Œã‚‹ã‚ˆã†ãªå ´åˆã«ã‚‚é©ç”¨ã§ãã¾ã™ã€‚


# â–  ã‚¤ãƒ³ãƒˆãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆä½•ã‚’ã—ãŸã„ã‹ï¼Ÿï¼‰

## 1. Introduction

- The vibrotactile sense enables humans to perceive texture surface properties through tool-surface interaction. Unfortunately, the richness of the vibrotactile responses from virtual texture surfaces is missing from current tool-surface interactions on a touchscreen. The tool-surface interactions are composed of simple gestures such as tapping or flickering, so vibrotactile designer should find the appropriate vibrotactile signals for each gesture. However, it is difficult to find ones. Though there are vibrotactile datasets which is made public, it is rare to find the appropriate vibrotactile signals from them. It is because such datasets contains at most 100 kinds of textures, as compared to countless kind of texture in the real world.
    - æŒ¯å‹•è§¦è¦šã¯äººé–“ãŒé“å…· - è¡¨é¢ç›¸äº’ä½œç”¨ã‚’é€šã—ã¦ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ¼è¡¨é¢ç‰¹æ€§ã‚’çŸ¥è¦šã™ã‚‹ã“ã¨ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚ æ®‹å¿µãªã“ã¨ã«ã€ä»®æƒ³ãƒ†ã‚¯ã‚¹ãƒãƒ£è¡¨é¢ã‹ã‚‰ã®æŒ¯å‹•è§¦è¦šå¿œç­”ã®è±Šå¯Œã•ã¯ã€ã‚¿ãƒƒãƒã‚¹ã‚¯ãƒªãƒ¼ãƒ³ä¸Šã®ç¾åœ¨ã®ãƒ„ãƒ¼ãƒ« - è¡¨é¢ç›¸äº’ä½œç”¨ã‹ã‚‰æ¬ ã‘ã¦ã„ã‚‹ã€‚ ãƒ„ãƒ¼ãƒ«ã¨ã‚µãƒ¼ãƒ•ã‚§ã‚¹ã®ç›¸äº’ä½œç”¨ã¯ã€ã‚¿ãƒƒãƒ—ã‚„ã¡ã‚‰ã¤ããªã©ã®å˜ç´”ãªã‚¸ã‚§ã‚¹ãƒãƒ£ã§æ§‹æˆã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€æŒ¯å‹•è§¦è¦šè¨­è¨ˆè€…ã¯å„ã‚¸ã‚§ã‚¹ãƒãƒ£ã«é©ã—ãŸæŒ¯å‹•è§¦è¦šä¿¡å·ã‚’è¦‹ã¤ã‘ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ ã—ã‹ã—ã€è¦‹ã¤ã‘ã‚‹ã®ã¯é›£ã—ã„ã§ã™ã€‚ å…¬é–‹ã•ã‚Œã¦ã„ã‚‹æŒ¯å‹•è§¦è¦šãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒã‚ã‚Šã¾ã™ãŒã€ãã‚Œã‚‰ã‹ã‚‰é©åˆ‡ãªæŒ¯å‹•è§¦è¦šä¿¡å·ã‚’è¦‹ã¤ã‘ã‚‹ã“ã¨ã¯ç¨€ã§ã™ã€‚ ã“ã‚Œã¯ã€ç¾å®Ÿã®ä¸–ç•Œã§ã¯æ•°ãˆåˆ‡ã‚Œãªã„ã»ã©ã®ç¨®é¡ã®ãƒ†ã‚¯ã‚¹ãƒãƒ£ã¨æ¯”è¼ƒã—ã¦ã€ã“ã®ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¯æœ€å¤§100ç¨®é¡ã®ãƒ†ã‚¯ã‚¹ãƒãƒ£ãŒå«ã¾ã‚Œã¦ã„ã‚‹ãŸã‚ã§ã™ã€‚

---

- Instead of looking into datasets, vibrotactile modeling has been studied for a long time to provide such responses. However, there is no model that interactively generates vibrotactile responses based on the state of the tool and the state of the surfaces. Such model should learn the complex mapping between large input and output space; Inputs are state of the tool (ex. toolâ€™s velocity) and the state of the texture surface (ex. textureâ€™s attributes), on the other hand, outputs are vibrotactile signals. Considering a limitation of a representational power that a trained single model can have, it is difficult to train the model that get both states of the tool and state of the texture surface as input. In other words, there is a trade-off between the modelâ€™s interactivity for the tool's state and the one for the texture surfaceâ€™s state.
    - ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª¿ã¹ã‚‹ä»£ã‚ã‚Šã«ã€æŒ¯å‹•è§¦è¦šãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã¯ãã®ã‚ˆã†ãªå¿œç­”ã‚’æä¾›ã™ã‚‹ãŸã‚ã«é•·ã„é–“ç ”ç©¶ã•ã‚Œã¦ãã¾ã—ãŸã€‚ ã—ã‹ã—ã€ãƒ„ãƒ¼ãƒ«ã®çŠ¶æ…‹ã¨ã‚µãƒ¼ãƒ•ã‚§ã‚¹ã®çŠ¶æ…‹ã«åŸºã¥ã„ã¦å¯¾è©±çš„ã«æŒ¯å‹•è§¦è¦šå¿œç­”ã‚’ç”Ÿæˆã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ ãã®ã‚ˆã†ãªãƒ¢ãƒ‡ãƒ«ã¯å¤§ããªå…¥åŠ›ã¨å‡ºåŠ›ç©ºé–“ã®é–“ã®è¤‡é›‘ãªãƒãƒƒãƒ”ãƒ³ã‚°ã‚’å­¦ã¶ã¹ãã§ã™ã€‚ å…¥åŠ›ã¯ãƒ„ãƒ¼ãƒ«ã®çŠ¶æ…‹ï¼ˆä¾‹ï¼šãƒ„ãƒ¼ãƒ«ã®é€Ÿåº¦ï¼‰ã¨ãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚µãƒ¼ãƒ•ã‚§ã‚¹ã®çŠ¶æ…‹ï¼ˆä¾‹ï¼šãƒ†ã‚¯ã‚¹ãƒãƒ£ã®å±æ€§ï¼‰ã§ã™ã€‚ä¸€æ–¹ã€å‡ºåŠ›ã¯æŒ¯å‹•è§¦è¦šä¿¡å·ã§ã™ã€‚ è¨“ç·´ã•ã‚ŒãŸå˜ä¸€ãƒ¢ãƒ‡ãƒ«ãŒæŒã¤ã“ã¨ãŒã§ãã‚‹è¡¨ç¾åŠ›ã®åˆ¶é™ã‚’è€ƒæ…®ã™ã‚‹ã¨ã€ãƒ„ãƒ¼ãƒ«ã®çŠ¶æ…‹ã¨ãƒ†ã‚¯ã‚¹ãƒãƒ£è¡¨é¢ã®çŠ¶æ…‹ã®ä¸¡æ–¹ã‚’å…¥åŠ›ã¨ã—ã¦å¾—ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹ã“ã¨ã¯å›°é›£ã§ã™ã€‚ ã¤ã¾ã‚Šã€ãƒ„ãƒ¼ãƒ«ã®çŠ¶æ…‹ã«å¯¾ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®å¯¾è©±æ€§ã¨ãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚µãƒ¼ãƒ•ã‚§ã‚¹ã®çŠ¶æ…‹ã«å¯¾ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®å¯¾è©±æ€§ã®é–“ã«ã¯ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ãŒã‚ã‚Šã¾ã™ã€‚

> ã“ã“ã§ã„ã†ãƒ„ãƒ¼ãƒ«ã¨ã¯ï¼Ÿï¼šã‚¿ãƒ–ãƒ¬ãƒƒãƒˆç«¯æœ«ãªã©ã®ã“ã¨

---

- Emerging, recent data-driven approach for haptic modeling mainly focus on the interactivity of the toolâ€™s state. Prior studies mapped the normal force and the velocity magnitude of the tool with vibrational patterns [1, 2]. These vibrational patterns were encoded in the autoregressive model. Their model succeeded in mapping the toolâ€™s state and the vibration patterns. They are suitable for interactions where there is much variability with toolâ€™s velocity and applied force. However, the single model generating vibrational signals only supported single kind of texture that is used during training. Thus, when you try to generate vibrations of another kind of texture, you need to replace the model with another one.
    - ãƒãƒ—ãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã«å¯¾ã™ã‚‹æœ€è¿‘ã®ãƒ‡ãƒ¼ã‚¿é§†å‹•å‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€ä¸»ã«ãƒ„ãƒ¼ãƒ«ã®çŠ¶æ…‹ã®å¯¾è©±æ€§ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚ ä»¥å‰ã®ç ”ç©¶ã§ã¯ã€ãƒ„ãƒ¼ãƒ«ã®å‚ç›´åŠ›ã¨é€Ÿåº¦ã®å¤§ãã•ã‚’æŒ¯å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ãƒãƒƒãƒ”ãƒ³ã‚°ã—ã¾ã—ãŸ[1ã€2]ã€‚ ã“ã‚Œã‚‰ã®æŒ¯å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯è‡ªå·±å›å¸°ãƒ¢ãƒ‡ãƒ«ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã™ã€‚ å½¼ã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒ„ãƒ¼ãƒ«ã®çŠ¶æ…‹ã¨æŒ¯å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒãƒƒãƒ”ãƒ³ã‚°ã™ã‚‹ã“ã¨ã«æˆåŠŸã—ã¾ã—ãŸã€‚ ãã‚Œã‚‰ã¯ã€ãƒ„ãƒ¼ãƒ«ã®é€Ÿåº¦ã‚„åŠ ãˆã‚‰ã‚ŒãŸåŠ›ã«å¤§ããªã°ã‚‰ã¤ããŒã‚ã‚‹ç›¸äº’ä½œç”¨ã«é©ã—ã¦ã„ã¾ã™ã€‚ ãŸã ã—ã€æŒ¯å‹•ä¿¡å·ã‚’ç”Ÿæˆã™ã‚‹å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«ä½¿ç”¨ã•ã‚Œã‚‹å˜ä¸€ç¨®é¡ã®ãƒ†ã‚¯ã‚¹ãƒãƒ£ã®ã¿ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã—ãŸã€‚ ã—ãŸãŒã£ã¦ã€åˆ¥ã®ç¨®é¡ã®ãƒ†ã‚¯ã‚¹ãƒãƒ£ã®æŒ¯å‹•ã‚’ç”Ÿæˆã—ã‚ˆã†ã¨ã™ã‚‹ã¨ã€ãƒ¢ãƒ‡ãƒ«ã‚’åˆ¥ã®ãƒ¢ãƒ‡ãƒ«ã¨ç½®ãæ›ãˆã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

---

- This paper, on the other hand, focuses on the interactivity for the textureâ€™s state instead of the toolâ€™s state. 
    - ã“ã‚Œã«å¯¾ã—ã¦ã€ã“ã®ãƒ›ãƒ¯ã‚¤ãƒˆãƒšãƒ¼ãƒ‘ãƒ¼ã§ã¯ã€ãƒ„ãƒ¼ãƒ«ã®çŠ¶æ…‹ã§ã¯ãªããƒ†ã‚¯ã‚¹ãƒãƒ£ã®çŠ¶æ…‹ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚

- Current touchscreen interactions are composed of simple gestures such as tapping or flickering, which is completed in a short time. With such gestures, the toolâ€™s velocity or applied force is approximately constant. On the other hand, such gestures are generally used for various texture surfaces. Thus, we pose the modeling task of generating appropriate vibrotactile signals that correspond to the visual information or attributes of texture.
    - **ç¾åœ¨ã®ã‚¿ãƒƒãƒã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã®æ“ä½œã¯ã€ã‚¿ãƒƒãƒ—ã‚„ãƒ•ãƒªãƒƒã‚¯ãªã©ã®ç°¡å˜ãªã‚¸ã‚§ã‚¹ãƒãƒ£ã§æ§‹æˆã•ã‚Œã¦ãŠã‚Šã€çŸ­æ™‚é–“ã§å®Œäº†ã—ã¾ã™ã€‚ã“ã®ã‚ˆã†ãªã‚¸ã‚§ã‚¹ãƒãƒ£ã§ã¯ã€ãƒ„ãƒ¼ãƒ«ã®é€Ÿåº¦ã¾ãŸã¯åŠ ãˆã‚‰ã‚Œã‚‹åŠ›ã¯ã»ã¼ä¸€å®šã§ã™ã€‚ä¸€æ–¹ã€ãã®ã‚ˆã†ãªã‚¸ã‚§ã‚¹ãƒãƒ£ã¯ä¸€èˆ¬ã«æ§˜ã€…ãªãƒ†ã‚¯ã‚¹ãƒãƒ£è¡¨é¢ã«ä½¿ç”¨ã•ã‚Œã‚‹ã€‚ã—ãŸãŒã£ã¦ã€æˆ‘ã€…ã¯è¦–è¦šçš„æƒ…å ±ã¾ãŸã¯ãƒ†ã‚¯ã‚¹ãƒãƒ£ã®å±æ€§ã«å¯¾å¿œã™ã‚‹é©åˆ‡ãªæŒ¯å‹•è§¦è¦šä¿¡å·ã‚’ç”Ÿæˆã™ã‚‹ã¨ã„ã†ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ä½œæ¥­ã‚’æèµ·ã™ã‚‹ã€‚**

- Such capabilities realize generating haptic signals for even unseen textures automatically or manipulating vibrotactile signals by changing attribute values. As an application of this model, we assume a vibrotactile designing toolkit for tool-surface interactions where designers can (1) set attributes of texture or (2) prepare texture images to generate the appropriate signals for gestures. The model that accomplishes it is required to have the capability to capture rich distribution.
    - ã“ã®ã‚ˆã†ãªæ©Ÿèƒ½ã«ã‚ˆã‚Šã€ç›®ã«è¦‹ãˆãªã„ãƒ†ã‚¯ã‚¹ãƒãƒ£ã«å¯¾ã—ã¦ã‚‚è§¦è¦šä¿¡å·ã‚’è‡ªå‹•çš„ã«ç”Ÿæˆã—ãŸã‚Šã€å±æ€§å€¤ã‚’å¤‰æ›´ã—ã¦æŒ¯å‹•è§¦è¦šä¿¡å·ã‚’æ“ä½œã—ãŸã‚Šã§ãã¾ã™ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã®å¿œç”¨ã¨ã—ã¦ã€è¨­è¨ˆè€…ãŒï¼ˆï¼‘ï¼‰ãƒ†ã‚¯ã‚¹ãƒãƒ£ã®å±æ€§ã‚’è¨­å®šã™ã‚‹ã€ã¾ãŸã¯ï¼ˆï¼’ï¼‰ã‚¸ã‚§ã‚¹ãƒãƒ£ã«é©åˆ‡ãªä¿¡å·ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã«ãƒ†ã‚¯ã‚¹ãƒãƒ£ç”»åƒã‚’æº–å‚™ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€ãƒ„ãƒ¼ãƒ« - ã‚µãƒ¼ãƒ•ã‚§ã‚¹ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ç”¨ã®æŒ¯å‹•è§¦è¦šè¨­è¨ˆãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆã‚’æƒ³å®šã™ã‚‹ã€‚ãã‚Œã‚’é”æˆã™ã‚‹ãŸã‚ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€è±Šã‹ãªæµé€šã‚’æ‰ãˆã‚‹èƒ½åŠ›ã‚’æŒã¤ã“ã¨ãŒå¿…è¦ã§ã™ã€‚

---

- Recently, generative methods that produce novel samples from high-dimensional data distributions, such as images, are finding widespread use. Specifically, Generative Adversarial Networks (GANs) [3] have shown promising results in synthesizing real-world images. Prior research demonstrated that GANs could effectively generate images conditioned on labels [4], texts [5], and so on. In spite of these promising results, there are few studies that used GANs to model time-series data distribution. Indeed, the generation of vibration by GANs has not been realized for now. In this study, we make full use of GANs for indirectly generating vibrotactile signals via time-frequency domain representation, which can be calculated as the image. We train the model so that it can generate vibrotactile signals conditioned on texture images or texture attributes.
    - æœ€è¿‘ã€ç”»åƒã®ã‚ˆã†ãªé«˜æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒã‹ã‚‰æ–°è¦ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆã™ã‚‹ç”Ÿæˆæ³•ãŒåºƒãä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã€‚ å…·ä½“çš„ã«ã¯ã€Generative Adversarial Networksï¼ˆGANï¼‰[3]ã¯ã€å®Ÿä¸–ç•Œã®ç”»åƒã®åˆæˆã«ãŠã„ã¦æœ‰æœ›ãªçµæœã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ ä»¥å‰ã®ç ”ç©¶ã§ã¯ã€GANãŒãƒ©ãƒ™ãƒ«[4]ã€ãƒ†ã‚­ã‚¹ãƒˆ[5]ãªã©ã«åŸºã¥ã„ã¦èª¿æ•´ã•ã‚ŒãŸç”»åƒã‚’åŠ¹æœçš„ã«ç”Ÿæˆã§ãã‚‹ã“ã¨ãŒå®Ÿè¨¼ã•ã‚Œã¾ã—ãŸã€‚ ã“ã‚Œã‚‰ã®æœ‰æœ›ãªçµæœã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã™ã‚‹ãŸã‚ã«GANã‚’ä½¿ç”¨ã—ãŸç ”ç©¶ã¯ã»ã¨ã‚“ã©ã‚ã‚Šã¾ã›ã‚“ã€‚ ç¢ºã‹ã«ã€GANã«ã‚ˆã‚‹æŒ¯å‹•ã®ç™ºç”Ÿã¯ä»Šã®ã¨ã“ã‚å®Ÿç¾ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ æœ¬ç ”ç©¶ã§ã¯ã€ç”»åƒã¨ã—ã¦è¨ˆç®—ã™ã‚‹ã“ã¨ãŒã§ãã‚‹æ™‚é–“ - å‘¨æ³¢æ•°é ˜åŸŸè¡¨ç¾ã‚’ä»‹ã—ã¦é–“æ¥çš„ã«æŒ¯å‹•è§¦è¦šä¿¡å·ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã«GANã‚’æœ€å¤§é™ã«åˆ©ç”¨ã™ã‚‹ã€‚ ãƒ†ã‚¯ã‚¹ãƒãƒ£ç”»åƒã¾ãŸã¯ãƒ†ã‚¯ã‚¹ãƒãƒ£å±æ€§ã«åŸºã¥ã„ã¦èª¿æ•´ã•ã‚ŒãŸæŒ¯å‹•è§¦è¦šä¿¡å·ã‚’ç”Ÿæˆã§ãã‚‹ã‚ˆã†ã«ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã™ã€‚

---

- The contribution of this study is three-fold. First, to our best knowledge, we introduce the problem of vibrotactile generation and are the first to use GANs to solve it. Second, we succeed in indirectly generate time-series data via time-frequency representation using GANs. Third, our trained single model meets the demand for interactiveness for the state of textures by providing the appropriate vibration that corresponds to the texture images or texture attributes.
    - ã“ã®ç ”ç©¶ã®è²¢çŒ®ã¯3å€ã§ã™ã€‚ ã¾ãšã€ç§ãŸã¡ã®çŸ¥ã‚‹é™ã‚Šã§ã¯ã€æŒ¯å‹•è§¦è¦šç”Ÿæˆã®å•é¡Œã‚’ç´¹ä»‹ã—ã€ãã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«GANã‚’ä½¿ç”¨ã™ã‚‹æœ€åˆã®ã‚‚ã®ã§ã™ã€‚ æ¬¡ã«ã€GANã‚’ç”¨ã„ãŸæ™‚é–“å‘¨æ³¢æ•°è¡¨ç¾ã«ã‚ˆã‚Šé–“æ¥çš„ã«æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã«æˆåŠŸã—ã¾ã—ãŸã€‚ ç¬¬ä¸‰ã«ã€ç§ãŸã¡ã®è¨“ç·´ã•ã‚ŒãŸå˜ä¸€ãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒ†ã‚¯ã‚¹ãƒãƒ£ç”»åƒã¾ãŸã¯ãƒ†ã‚¯ã‚¹ãƒãƒ£å±æ€§ã«å¯¾å¿œã™ã‚‹é©åˆ‡ãªæŒ¯å‹•ã‚’æä¾›ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã€ãƒ†ã‚¯ã‚¹ãƒãƒ£ã®çŠ¶æ…‹ã®ãŸã‚ã®å¯¾è©±æ€§ã«å¯¾ã™ã‚‹è¦æ±‚ã‚’æº€ãŸã—ã¾ã™ã€‚


# â–  çµè«–

## 5. Conclusion

- In this study, we introduced the problem of vibrotactile generation based on various texture images or attributes during predefined tool-surface interaction, and solved it by adversarial training. The user study showed that users could not discriminate generated signals and genuine ones. Our approach is applicable to any case where the users touch the various surfaces in a predefined way. Thus, our study contributes to the broadening the options of vibrotactile signal preparation in such cases.
    - æœ¬ç ”ç©¶ã§ã¯ã€äº‹å‰å®šç¾©ã•ã‚ŒãŸãƒ„ãƒ¼ãƒ«ã¨ã‚µãƒ¼ãƒ•ã‚§ã‚¹ã®ç›¸äº’ä½œç”¨ä¸­ã®ã•ã¾ã–ã¾ãªãƒ†ã‚¯ã‚¹ãƒãƒ£ç”»åƒã¾ãŸã¯å±æ€§ã«åŸºã¥ãæŒ¯å‹•è§¦è¦šç”Ÿæˆã®å•é¡Œã‚’ç´¹ä»‹ã—ã€ãã‚Œã‚’æ•µå¯¾è€…ã®è¨“ç·´ã«ã‚ˆã£ã¦è§£æ±ºã—ã¾ã—ãŸã€‚ ãƒ¦ãƒ¼ã‚¶ãƒ¼èª¿æŸ»ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç”Ÿæˆã•ã‚ŒãŸä¿¡å·ã¨æœ¬ç‰©ã®ä¿¡å·ã‚’åŒºåˆ¥ã§ããªã„ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ ç§ãŸã¡ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒäº‹å‰å®šç¾©ã•ã‚ŒãŸæ–¹æ³•ã§ã•ã¾ã–ã¾ãªã‚µãƒ¼ãƒ•ã‚§ã‚¹ã«è§¦ã‚Œã‚‹ã‚ˆã†ãªå ´åˆã«ã‚‚é©ç”¨ã§ãã¾ã™ã€‚ ã—ãŸãŒã£ã¦ã€æˆ‘ã€…ã®ç ”ç©¶ã¯ã€ãã®ã‚ˆã†ãªå ´åˆã®æŒ¯å‹•è§¦è¦šä¿¡å·å‡¦ç†ã®é¸æŠè‚¢ã‚’åºƒã’ã‚‹ã“ã¨ã«è²¢çŒ®ã—ã¦ã„ã¾ã™ã€‚

# â–  ä½•ã‚’ã—ãŸã‹ï¼Ÿè©³ç´°

## 3 Vibrotactile Signal Generation

### 3.1 Concept of Overall Model

- By utilizing GANsâ€™ capability to capture rich data distributions, we would like to make the single generative model that has following features: automatic generation of vibrotactile signals either (1) from given texture images or (2) from given texture attributes.
    - **GANã®è±Šå¯Œãªãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒã‚’æ‰ãˆã‚‹æ©Ÿèƒ½ã‚’åˆ©ç”¨ã—ã¦ã€ï¼ˆ1ï¼‰ä¸ãˆã‚‰ã‚ŒãŸãƒ†ã‚¯ã‚¹ãƒãƒ£ç”»åƒã‹ã‚‰ã€ã¾ãŸã¯ï¼ˆ2ï¼‰ä¸ãˆã‚‰ã‚ŒãŸãƒ†ã‚¯ã‚¹ãƒãƒ£å±æ€§ã‹ã‚‰ã€æŒ¯å‹•è§¦è¦šä¿¡å·ã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹ã¨ã„ã†å˜ä¸€ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚’ä½œã‚ŠãŸã„ã¨æ€ã„ã¾ã™ã€‚**

- Though prior research focuses on the interactive generation based on toolâ€™s state, this paper proves the concept above for predefined toolâ€™s state under constrained touch interactions. Among various touch interactions, we focus on the task of moving a pen on the texture surface.
    - ã“ã‚Œã¾ã§ã®ç ”ç©¶ã§ã¯ãƒ„ãƒ¼ãƒ«ã®çŠ¶æ…‹ã«åŸºã¥ãå¯¾è©±å‹ç”Ÿæˆã«ç„¦ç‚¹ãŒå½“ã¦ã‚‰ã‚Œã¦ã„ã¾ã—ãŸãŒã€ã“ã®ãƒ›ãƒ¯ã‚¤ãƒˆãƒšãƒ¼ãƒ‘ãƒ¼ã§ã¯ã€æ‹˜æŸã•ã‚ŒãŸã‚¿ãƒƒãƒæ“ä½œã®ä¸‹ã§ã®å®šç¾©æ¸ˆã¿ã®ãƒ„ãƒ¼ãƒ«ã®çŠ¶æ…‹ã«å¯¾ã™ã‚‹ä¸Šè¨˜ã®æ¦‚å¿µã‚’è¨¼æ˜ã—ã¾ã™ã€‚ **ã•ã¾ã–ã¾ãªã‚¿ãƒƒãƒæ“ä½œã®ä¸­ã§ã€ãƒ†ã‚¯ã‚¹ãƒãƒ£è¡¨é¢ä¸Šã§ãƒšãƒ³ã‚’å‹•ã‹ã™ä½œæ¥­ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚**

---

- The overall diagram of our model is shown in Fig. 1. It consists of two parts: an encoder network, and a generator network. They are trained separately. The encoder is trained as an image classifier and it encodes texture images into a label vector c. The generator is trained with discriminator in GANs training framework and generates spectrogram that is a representation of vibration in a time-frequency domain. We describe the training details for each network in the following sections. The overall model enables end-to-end generation from visual images or label attributes of texture to the vibrotactile wave.
    - **ã“ã®ãƒ¢ãƒ‡ãƒ«ã®å…¨ä½“å›³ã‚’å›³1ã«ç¤ºã—ã¾ã™ã€‚ã“ã‚Œã¯ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¨ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®2ã¤ã®éƒ¨åˆ†ã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚ å½¼ã‚‰ã¯åˆ¥ã€…ã«è¨“ç·´ã•ã‚Œã¦ã„ã¾ã™ã€‚**
    - **ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¯ç”»åƒåˆ†é¡å­ã¨ã—ã¦è¨“ç·´ã•ã‚Œã€ãƒ†ã‚¯ã‚¹ãƒãƒ£ç”»åƒã‚’ãƒ©ãƒ™ãƒ«ãƒ™ã‚¯ãƒˆãƒ«cã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¾ã™ã€‚**
    - **ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã¯ã€GANãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§å¼åˆ¥å™¨ã‚’ä½¿ç”¨ã—ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã€æ™‚é–“ - å‘¨æ³¢æ•°é ˜åŸŸã§ã®æŒ¯å‹•ã®è¡¨ç¾ã§ã‚ã‚‹ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã‚’ç”Ÿæˆã—ã¾ã™ã€‚**
    - æ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€å„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®è©³ç´°ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚ å…¨ä½“çš„ãªãƒ¢ãƒ‡ãƒ«ã¯ã€è¦–è¦šçš„ãªç”»åƒã‚„ãƒ†ã‚¯ã‚¹ãƒãƒ£ã®ãƒ©ãƒ™ãƒ«å±æ€§ã‹ã‚‰æŒ¯å‹•è§¦è¦šæ³¢ã¾ã§ã®ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®ç”Ÿæˆã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚

---

- We describe the data flow step by step based on Fig. 1. The input into the model is either a class label that represents the tactile attributes of the texture or a texture image. When the image is input, the label vector c is extracted from the texture image through encoder network. The label vector c is a categorical variable that shows the attributes of the texture. Next, the label vector c is passed into the generator network. The generator concatenates the label c and the random noise z and transforms them into the spectrogram. 
    - å›³1ã«åŸºã¥ã„ã¦ã€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ã‚’æ®µéšçš„ã«èª¬æ˜ã—ã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã¸ã®å…¥åŠ›ã¯ã€ãƒ†ã‚¯ã‚¹ãƒãƒ£ã®è§¦è¦šå±æ€§ã‚’è¡¨ã™ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ã¾ãŸã¯ãƒ†ã‚¯ã‚¹ãƒãƒ£ç”»åƒã®ã„ãšã‚Œã‹ã§ã™ã€‚
    - ç”»åƒãŒå…¥åŠ›ã•ã‚Œã‚‹ã¨ã€ãƒ©ãƒ™ãƒ«ãƒ™ã‚¯ãƒˆãƒ«ï½ƒãŒã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’é€šã—ã¦ãƒ†ã‚¯ã‚¹ãƒãƒ£ç”»åƒã‹ã‚‰æŠ½å‡ºã•ã‚Œã‚‹ã€‚ ãƒ©ãƒ™ãƒ«ãƒ™ã‚¯ãƒˆãƒ«cã¯ã€ãƒ†ã‚¯ã‚¹ãƒãƒ£ã®å±æ€§ã‚’ç¤ºã™è³ªçš„å¤‰æ•°ã§ã™ã€‚
    - æ¬¡ã«ã€ãƒ©ãƒ™ãƒ«ãƒ™ã‚¯ãƒˆãƒ«cãŒã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«æ¸¡ã•ã‚Œã¾ã™ã€‚ ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã¯ãƒ©ãƒ™ãƒ«cã¨ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚ºzã‚’é€£çµã—ã€ãã‚Œã‚‰ã‚’ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã«å¤‰æ›ã—ã¾ã™ã€‚

- The generated spectrogram is converted into the acceleration wave format by Griffin-Lim algorithm [10]. Then the wave format data is output to the user. With this overall model, users can input either label information or texture images to obtain vibration. That is why we do not adopt the network like pix2pix [6], which only supports input as images and converts images directory into signals.
    - ç”Ÿæˆã•ã‚ŒãŸã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã¯ã€Griffin-Limã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ [10]ã«ã‚ˆã£ã¦åŠ é€Ÿåº¦æ³¢ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›ã•ã‚Œã¾ã™ã€‚ ãã—ã¦ã€ãã®æ³¢å½¢ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ¦ãƒ¼ã‚¶ã«å‡ºåŠ›ã™ã‚‹ã€‚ ã“ã®å…¨ä½“ãƒ¢ãƒ‡ãƒ«ã§ã¯ã€ãƒ¦ãƒ¼ã‚¶ã¯ãƒ©ãƒ™ãƒ«æƒ…å ±ã¾ãŸã¯ãƒ†ã‚¯ã‚¹ãƒãƒ£ç”»åƒã‚’å…¥åŠ›ã—ã¦æŒ¯å‹•ã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ ãã®ãŸã‚ã€ç”»åƒã¨ã—ã¦ã®å…¥åŠ›ã®ã¿ã‚’ã‚µãƒãƒ¼ãƒˆã—ã€ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä¿¡å·ã«å¤‰æ›ã™ã‚‹pix2pix [6]ã®ã‚ˆã†ãªãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æ¡ç”¨ã—ã¦ã„ã¾ã›ã‚“ã€‚

---

- Acceleration signals are used as vibrotactile stimulus in our model. In order to train the whole network, we use dataset [11], which contains acceleration signals and captured images during movement task. The pairs of signals and images are annotated with 108 classes.
    - **åŠ é€Ÿåº¦ä¿¡å·ã¯ã€ç§ãŸã¡ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯æŒ¯å‹•è§¦è¦šåˆºæ¿€ã¨ã—ã¦ä½¿ã‚ã‚Œã¦ã„ã¾ã™ã€‚ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å…¨ä½“ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ãŸã‚ã«ã€æˆ‘ã€…ã¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ[11]ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ã“ã‚Œã«ã¯ã€ç§»å‹•ã‚¿ã‚¹ã‚¯ä¸­ã«åŠ é€Ÿåº¦ä¿¡å·ã¨ã‚­ãƒ£ãƒ—ãƒãƒ£ã•ã‚ŒãŸç”»åƒãŒå«ã¾ã‚Œã¾ã™ã€‚ ä¿¡å·ã¨ç”»åƒã®ãƒšã‚¢ã«ã¯108ã®ã‚¯ãƒ©ã‚¹ãŒä»˜ã„ã¦ã„ã¾ã™ã€‚**

### 3.2 Encoder

- We trained the image encoder that encoded texture images into the label vector c. We adopted the deep residual network (ResNet-50) [12] architecture. We fine-tuned all the layers of the ResNet-50 that had been pre-trained with ImageNet [13]. We used Adam optimizer with a mini-batch size of 64. The learning rate started from 1e-3 and was decreased by a factor of 0.1 when the training error plateaued.
    - ãƒ†ã‚¯ã‚¹ãƒãƒ£ç”»åƒã‚’ãƒ©ãƒ™ãƒ«ãƒ™ã‚¯ãƒˆãƒ«cã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹ç”»åƒã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‚’è¨“ç·´ã—ã¾ã—ãŸã€‚ æˆ‘ã€…ã¯ãƒ‡ã‚£ãƒ¼ãƒ—æ®‹å·®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆResNet-50ï¼‰[12]ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ¡ç”¨ã—ãŸã€‚ ImageNetã§äº‹å‰ã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸResNet-50ã®ã™ã¹ã¦ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’å¾®èª¿æ•´ã—ã¾ã—ãŸ[13]ã€‚ Adamã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã‚’ãƒŸãƒ‹ãƒãƒƒãƒã‚µã‚¤ã‚º64ã§ä½¿ç”¨ã—ã¾ã—ãŸã€‚å­¦ç¿’ç‡ã¯1e-3ã‹ã‚‰å§‹ã¾ã‚Šã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼ãŒæ¨ªã°ã„ã«ãªã£ãŸã¨ãã¯0.1å€æ¸›å°‘ã—ã¾ã—ãŸã€‚

---

- The size of provided images by [11] is 320 x 480. We fed them into the encoder network. For training phase of encoder network, we followed ordinary data augmentation settings. We scaled an image with factors in [1, 1.3], randomly cropped 128 x 128 size of it, flipped it horizontally and vertically, rotated it by a random angle. The recent data augmentation technique of random erasing and mixup were also used.
    - [11]ã§æä¾›ã•ã‚Œã‚‹ç”»åƒã®ã‚µã‚¤ã‚ºã¯320 x 480ã§ã™ã€‚ç§ãŸã¡ã¯ãã‚Œã‚‰ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«é€ã‚Šã¾ã—ãŸã€‚ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ã‚§ãƒ¼ã‚ºã§ã¯ã€é€šå¸¸ã®ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µè¨­å®šã«å¾“ã„ã¾ã—ãŸã€‚ ç”»åƒã‚’[1ã€1.3]ã®ä¿‚æ•°ã§æ‹¡å¤§ç¸®å°ã—ã€ã‚µã‚¤ã‚ºã‚’128 x 128ã®ã‚µã‚¤ã‚ºã§ãƒ©ãƒ³ãƒ€ãƒ ã«ãƒˆãƒªãƒŸãƒ³ã‚°ã—ã€æ°´å¹³æ–¹å‘ã¨å‚ç›´æ–¹å‘ã«åè»¢ã•ã›ã€ãƒ©ãƒ³ãƒ€ãƒ ãªè§’åº¦ã§å›è»¢ã•ã›ã¾ã—ãŸã€‚ ãƒ©ãƒ³ãƒ€ãƒ æ¶ˆå»ãŠã‚ˆã³æ··åˆã®æœ€è¿‘ã®ãƒ‡ãƒ¼ã‚¿å¢—å¼·æŠ€è¡“ã‚‚ä½¿ç”¨ã•ã‚ŒãŸã€‚

---

- As a result of training, the trained encoder achieved a classification accuracy of more than 95 percent on the testing set. After the network was trained, its last layer was removed, and the feature vector of the second to the last layer having dimension of label vector was used as the image encoding in our generator network.
    - ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®çµæœã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å—ã‘ãŸã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¯ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§95ï¼…ä»¥ä¸Šã®åˆ†é¡ç²¾åº¦ã‚’é”æˆã—ã¾ã—ãŸã€‚ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãŒè¨“ç·´ã•ã‚ŒãŸå¾Œã€ãã®æœ€å¾Œã®å±¤ãŒé™¤å»ã•ã‚Œã€ãƒ©ãƒ™ãƒ«ãƒ™ã‚¯ãƒˆãƒ«ã®æ¬¡å…ƒã‚’æœ‰ã™ã‚‹æœ€å¾Œã‹ã‚‰äºŒç•ªç›®ã®å±¤ã®ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ãŒã€æˆ‘ã€…ã®ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«ãŠã‘ã‚‹ç”»åƒç¬¦å·åŒ–ã¨ã—ã¦ä½¿ç”¨ã•ã‚ŒãŸã€‚

### 3.3 Generator

#### Network Architecture and training settings.

- Generator was trained with discriminator in GANs framework. During training, the discriminator learned to discriminate between genuine and generated samples, while the generator learned to fool the discriminator. Generator output samples ğ‘¥ = ğº(ğ‘§, ğ‘) conditioned on both random noise vector z and a label vector c from dataset. Discriminator had two outputs: D(x) the probability of the sample x being genuine, and ğ‘ƒ(ğ‘¥) = ğ’„, the predicted label vector of x. After training, the discriminator was removed and the generator was only used in our model. 
    - ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã¯GANã®æ çµ„ã¿ã§å¼åˆ¥å™¨ã§è¨“ç·´ã•ã‚Œã¾ã—ãŸã€‚ è¨“ç·´ä¸­ã€å¼åˆ¥å™¨ã¯æœ¬ç‰©ã®ã‚µãƒ³ãƒ—ãƒ«ã¨ç”Ÿæˆã•ã‚ŒãŸã‚µãƒ³ãƒ—ãƒ«ã‚’åŒºåˆ¥ã™ã‚‹ã“ã¨ã‚’å­¦ã³ã€ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã¯å¼åˆ¥å™¨ã‚’ã ã¾ã™ã“ã¨ã‚’å­¦ã³ã¾ã—ãŸã€‚ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰ã®ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚ºãƒ™ã‚¯ãƒˆãƒ«zã¨ãƒ©ãƒ™ãƒ«ãƒ™ã‚¯ãƒˆãƒ«cã®ä¸¡æ–¹ã«åŸºã¥ã„ã¦ç”Ÿæˆã•ã‚ŒãŸç”Ÿæˆå™¨å‡ºåŠ›ã‚µãƒ³ãƒ—ãƒ«ğ‘¥=ğºï¼ˆğ‘§ã€ğ‘ï¼‰ã€‚ è­˜åˆ¥å™¨ã«ã¯2ã¤ã®å‡ºåŠ›ãŒã‚ã‚Šã¾ã™ã€‚ã‚µãƒ³ãƒ—ãƒ«xãŒæœ¬ç‰©ã§ã‚ã‚‹ç¢ºç‡Dï¼ˆxï¼‰ã€ãŠã‚ˆã³xã®äºˆæ¸¬ãƒ©ãƒ™ãƒ«ãƒ™ã‚¯ãƒˆãƒ«ã§ã‚ã‚‹ğ‘ƒï¼ˆğ‘¥ï¼‰=ğ’„ã€‚ è¨“ç·´ã®å¾Œã€å¼åˆ¥å™¨ã¯å–ã‚Šé™¤ã‹ã‚Œã€ç™ºç”Ÿå™¨ã¯æˆ‘ã€…ã®ãƒ¢ãƒ‡ãƒ«ã§ã®ã¿ä½¿ç”¨ã•ã‚Œã¾ã—ãŸã€‚

- Inspired by [14], we employed architecture and loss function, which was based on SRResNet[7], DRAGAN[15], and AC-GAN[8]. The architecture of generator and discriminator are shown in Fig. 2.
    - **[14]ã«è§¦ç™ºã•ã‚Œã¦ã€SRResNet [7]ã€DRAGAN [15]ã€AC-GAN [8]ã«åŸºã¥ã„ãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨æå¤±é–¢æ•°ã‚’æ¡ç”¨ã—ã¾ã—ãŸã€‚ ç”Ÿæˆå™¨ã¨è­˜åˆ¥å™¨ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’å›³2ã«ç¤ºã—ã¾ã™ã€‚**

---

- Acceleration signals orthogonal to the surface during movement task were used as vibrotactile stimulus and we aim at generating the signals by generator. For now, there are few studies generating time series data using GANs. It is because GANs are poor at generating time-series data though they are good at generating 2D images. Therefore, we chose amplitude spectrogram as a representation of the acceleration signals and trained GANs to generate spectrogram as if that was 2D image. The same dataset used for training encoder contained acceleration signals during movement task. Each signal had 4 seconds long and the sampling rate was 10 kHz. We computed the spectrogram from wave format using 512-point Short-Time Fourier Transform (STFT) with a 512 hamming window and a 128 hop size. Then, the linear amplitude of the spectrogram was converted to the logarithmic scale. We cropped the spectrogram and resized it into 128 x 128 size. As a result, the spectrogram contained the information of time- frequency domain up to 256 Hz for 1.625 seconds long. The values in the spectrogram were normalized into the range from 0 to 1.
    - é‹å‹•èª²é¡Œä¸­ã«è¡¨é¢ã«ç›´äº¤ã™ã‚‹åŠ é€Ÿåº¦ä¿¡å·ã‚’æŒ¯å‹•è§¦è¦šåˆºæ¿€ã¨ã—ã¦ä½¿ç”¨ã—ã€ãã—ã¦æˆ‘ã€…ã¯ä¿¡å·ã‚’ç™ºç”Ÿå™¨ã«ã‚ˆã£ã¦ç™ºç”Ÿã•ã›ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã™ã‚‹ã€‚ä»Šã®ã¨ã“ã‚ã€GANã‚’ä½¿ç”¨ã—ã¦æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ç ”ç©¶ã¯ã»ã¨ã‚“ã©ã‚ã‚Šã¾ã›ã‚“ã€‚ã“ã‚Œã¯ã€GANãŒ2Dç”»åƒã®ç”Ÿæˆã«ã¯é•·ã‘ã¦ã„ã‚‹ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆã«ã¯é•·ã‘ã¦ã„ã‚‹ãŸã‚ã§ã™ã€‚ã—ãŸãŒã£ã¦ã€åŠ é€Ÿåº¦ä¿¡å·ã¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸGANã®è¡¨ç¾ã¨ã—ã¦æŒ¯å¹…ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã‚’é¸æŠã—ã€ãã‚ŒãŒã‚ãŸã‹ã‚‚2Dç”»åƒã§ã‚ã‚‹ã‹ã®ã‚ˆã†ã«ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ä½¿ç”¨ã•ã‚ŒãŸã‚‚ã®ã¨åŒã˜ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¯ã€ç§»å‹•ã‚¿ã‚¹ã‚¯ä¸­ã®åŠ é€Ÿåº¦ä¿¡å·ãŒå«ã¾ã‚Œã¦ã„ã¾ã—ãŸã€‚å„ä¿¡å·ã®é•·ã•ã¯4ç§’ã§ã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆã¯10 kHzã§ã™ã€‚æˆ‘ã€…ã¯ã€512ãƒãƒŸãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã¨128ãƒ›ãƒƒãƒ—ã‚µã‚¤ã‚ºã®512ãƒã‚¤ãƒ³ãƒˆçŸ­æ™‚é–“ãƒ•ãƒ¼ãƒªã‚¨å¤‰æ›ï¼ˆSTFTï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€ã‚¦ã‚§ãƒ¼ãƒ–ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‹ã‚‰ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã‚’è¨ˆç®—ã—ã¾ã—ãŸã€‚æ¬¡ã«ã€ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã®ç·šå½¢æŒ¯å¹…ã‚’å¯¾æ•°ç›®ç››ã«å¤‰æ›ã—ãŸã€‚ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ã—ã¦ã€ã‚µã‚¤ã‚ºã‚’128 x 128ã«å¤‰æ›´ã—ã¾ã—ãŸã€‚ãã®çµæœã€ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã¯1.625ç§’é–“ã§æœ€å¤§256Hzã¾ã§ã®æ™‚é–“å‘¨æ³¢æ•°é ˜åŸŸã®æƒ…å ±ã‚’å«ã‚“ã§ã„ãŸã€‚ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã®å€¤ã¯ã€0ã‹ã‚‰1ã®ç¯„å›²ã«æ­£è¦åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚

---

- We selected 9 textures out of 108 textures for GANsâ€™ training because it is stable to train conditional GANs with fewer number of conditional label dimensions. Thus, the dimension of categorical label c was 9. On the other hand, the dimension of noise z was 50. The selected 9 textures were representative of 9 groups of LMT haptic texture database [11] (Fig. 3). We used Adam optimizer with a mini-batch size of 64. The learning rate was fixed at 2e-4.
    - GANã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã«108å€‹ã®ãƒ†ã‚¯ã‚¹ãƒãƒ£ã‹ã‚‰9å€‹ã®ãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚’é¸æŠã—ã¾ã—ãŸã€‚æ¡ä»¶ä»˜ããƒ©ãƒ™ãƒ«æ¬¡å…ƒã®æ•°ãŒå°‘ãªã„æ¡ä»¶ä»˜ãGANã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã®ãŒå®‰å®šã—ã¦ã„ã‚‹ãŸã‚ã§ã™ã€‚ ã—ãŸãŒã£ã¦ã€ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ãƒ©ãƒ™ãƒ«cã®æ¬¡å…ƒã¯9ã§ã—ãŸã€‚ä¸€æ–¹ã€ãƒã‚¤ã‚ºzã®æ¬¡å…ƒã¯50ã§ã—ãŸã€‚é¸æŠã•ã‚ŒãŸ9ã¤ã®ãƒ†ã‚¯ã‚¹ãƒãƒ£ã¯ã€LMTè§¦è¦šãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®9ã¤ã®ã‚°ãƒ«ãƒ¼ãƒ—ã‚’è¡¨ã—ã¦ã„ã¾ã—ãŸ[11]ï¼ˆå›³3ï¼‰ã€‚ Adamã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã‚’ãƒŸãƒ‹ãƒãƒƒãƒã‚µã‚¤ã‚º64ã§ä½¿ç”¨ã—ã¾ã—ãŸã€‚å­¦ç¿’ç‡ã¯2e-4ã«å›ºå®šã•ã‚Œã¾ã—ãŸã€‚

#### Training Results of Generator. 

- The spectrogram in test dataset and the one generated by generator are shown in Fig. 4. The comparison between them shows the trained generator could generate the spectrograms that appear indistinguishable from test ones. We describe the qualitative evaluation by user study in section 4. 
    - ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã¨generatorã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚ŒãŸã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã‚’å›³4ã«ç¤ºã—ã¾ã™ã€‚ãã‚Œã‚‰ã®æ¯”è¼ƒã‹ã‚‰ã€è¨“ç·´ã•ã‚ŒãŸã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãŒãƒ†ã‚¹ãƒˆã®ã‚‚ã®ã¨åŒºåˆ¥ãŒã¤ã‹ãªã„ã‚ˆã†ã«è¦‹ãˆã‚‹ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã‚’ç”Ÿæˆã§ãã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ã€‚ æˆ‘ã€…ã¯4ç« ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¹ã‚¿ãƒ‡ã‚£ã«ã‚ˆã‚‹å®šæ€§çš„è©•ä¾¡ã«ã¤ã„ã¦è¿°ã¹ã‚‹ã€‚
    
- On the other hand, it is generally difficult to quantitatively evaluate the GANs. The ordinary evaluation metric of GANs, namely the â€œinception scoreâ€ cannot to be applied to our case because the â€œinception scoreâ€ is only applied to standard dataset such as CIFAR-10. Instead, we observe that t-SNE is a good tool to examine the distribution of generated images. A two dimensional t-SNE visualization is shown in Fig. 5. It is shown that the generated and test samples made group for each class label.
    - ä¸€æ–¹ã€ä¸€èˆ¬çš„ã«GANã‚’å®šé‡çš„ã«è©•ä¾¡ã™ã‚‹ã“ã¨ã¯é›£ã—ã„ã€‚ ã€Œã‚¤ãƒ³ã‚»ãƒ—ã‚·ãƒ§ãƒ³ã‚¹ã‚³ã‚¢ã€ã¯CIFAR-10ãªã©ã®æ¨™æº–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã®ã¿é©ç”¨ã•ã‚Œã‚‹ãŸã‚ã€GANã®é€šå¸¸ã®è©•ä¾¡æŒ‡æ¨™ã€ã¤ã¾ã‚Šã€Œã‚¤ãƒ³ã‚»ãƒ—ã‚·ãƒ§ãƒ³ã‚¹ã‚³ã‚¢ã€ã‚’ç§ãŸã¡ã®ã‚±ãƒ¼ã‚¹ã«é©ç”¨ã™ã‚‹ã“ã¨ã¯ã§ãã¾ã›ã‚“ã€‚ ä»£ã‚ã‚Šã«ã€æˆ‘ã€…ã¯ã€t-SNEãŒç”Ÿæˆã•ã‚ŒãŸç”»åƒã®åˆ†å¸ƒã‚’èª¿ã¹ã‚‹ãŸã‚ã®è‰¯ã„ãƒ„ãƒ¼ãƒ«ã§ã‚ã‚‹ã“ã¨ã‚’è¦³å¯Ÿã—ã¾ã™ã€‚ äºŒæ¬¡å…ƒï½” âˆ’ ï¼³ï¼®ï¼¥è¦–è¦šåŒ–ã‚’å›³ï¼•ã«ç¤ºã™ã€‚ç”Ÿæˆã•ã‚ŒãŸã‚µãƒ³ãƒ—ãƒ«ãŠã‚ˆã³è©¦é¨“ã‚µãƒ³ãƒ—ãƒ«ãŒå„ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ã«ã¤ã„ã¦ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã•ã‚ŒãŸã“ã¨ãŒç¤ºã•ã‚Œã‚‹ã€‚


## 3.4 End-to end (E2E) Network

- E2E cross modal generation of signals from texture images are realized by combining encoder and generator. The encoder was trained with 9 classes instead of 108 classes in accordance with input dimension of conditional generator. Fig. 7shows the generated spectrogram from the texture image and genuine one for each test image in the dataset. The comparison between them shows the E2E network could generate the spectrograms that seem indistinguishable from test one. We describe the qualitative evaluation by user study in section 4.
    - ãƒ†ã‚¯ã‚¹ãƒãƒ£ç”»åƒã‹ã‚‰ã®ä¿¡å·ã®ï¼¥ï¼’ï¼¥ã‚¯ãƒ­ã‚¹ãƒ¢ãƒ¼ãƒ€ãƒ«ç”Ÿæˆã¯ã€ç¬¦å·å™¨ã¨ç”Ÿæˆå™¨ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã«ã‚ˆã£ã¦å®Ÿç¾ã•ã‚Œã‚‹ã€‚ æ¡ä»¶ä»˜ãã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã®å…¥åŠ›æ¬¡å…ƒã«å¾“ã£ã¦ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¯108ã‚¯ãƒ©ã‚¹ã§ã¯ãªã9ã‚¯ãƒ©ã‚¹ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã¾ã—ãŸã€‚ å›³ï¼—ã¯ã€ãƒ†ã‚¯ã‚¹ãƒãƒ£ç”»åƒã‹ã‚‰ç”Ÿæˆã•ã‚ŒãŸã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå†…ã®å„ãƒ†ã‚¹ãƒˆç”»åƒã«ã¤ã„ã¦ã®æœ¬ç‰©ã®ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã‚’ç¤ºã™ã€‚ ãã‚Œã‚‰ã®æ¯”è¼ƒã¯ã€E2Eãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãŒãƒ†ã‚¹ãƒˆã®ã‚‚ã®ã¨åŒºåˆ¥ãŒã¤ã‹ãªã„ã‚ˆã†ã«è¦‹ãˆã‚‹ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚ ç¬¬4ç¯€ã§ã¯åˆ©ç”¨è€…èª¿æŸ»ã«ã‚ˆã‚‹è³ªçš„è©•ä¾¡ã«ã¤ã„ã¦è¿°ã¹ã‚‹ã€‚



# â–  å®Ÿé¨“çµæœï¼ˆä¸»å¼µã®è¨¼æ˜ï¼‰ãƒ»è­°è«–ï¼ˆæ‰‹æ³•ã®è‰¯ã—æ‚ªã—ï¼‰ãƒ»ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆå®Ÿé¨“æ–¹æ³•ï¼‰

## 4 User study

- In user studies, participantsâ€™ task was to move a pen-type device on a surface of a tablet device while receiving vibrotactile feedback. Our experimental system was constituted of the tablet device (Apple Inc., iPad Pro 9.7 inch), an amplifier (Lepai Inc., LP-2020A +), and a pen-type device with a vibrator (Fig. 8). The pen-type device, which we handcrafted, is specifically described in the next paragraph.
    - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç ”ç©¶ã§ã¯ã€å‚åŠ è€…ã®ä»•äº‹ã¯ã€æŒ¯å‹•è§¦è¦šãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å—ã‘ãªãŒã‚‰ã€ã‚¿ãƒ–ãƒ¬ãƒƒãƒˆå‹ãƒ‡ãƒã‚¤ã‚¹ã®è¡¨é¢ã§ãƒšãƒ³å‹ãƒ‡ãƒã‚¤ã‚¹ã‚’å‹•ã‹ã™ã“ã¨ã§ã—ãŸã€‚ æˆ‘ã€…ã®å®Ÿé¨“ã‚·ã‚¹ãƒ†ãƒ ã¯ã€ã‚¿ãƒ–ãƒ¬ãƒƒãƒˆãƒ‡ãƒã‚¤ã‚¹ï¼ˆApple Inc.ã€iPad Pro 9.7ã‚¤ãƒ³ãƒï¼‰ã€ã‚¢ãƒ³ãƒ—ï¼ˆLepai Inc.ã€LP-2020A +ï¼‰ã€ãŠã‚ˆã³ãƒã‚¤ãƒ–ãƒ¬ãƒ¼ã‚¿ä»˜ããƒšãƒ³å‹ãƒ‡ãƒã‚¤ã‚¹ã‹ã‚‰æ§‹æˆã•ã‚Œã¦ã„ã¾ã—ãŸï¼ˆå›³8ï¼‰ã€‚ æˆ‘ã€…ãŒæ‰‹ä½œã‚Šã—ãŸãƒšãƒ³å‹è£…ç½®ã¯ã€æ¬¡ã®æ®µè½ã§å…·ä½“çš„ã«èª¬æ˜ã•ã‚Œã‚‹ã€‚

---

- The pen-type device was about 20 g weight and about 140 mm long. The diameter of the grip part of the pen was about 10 mm. The pen tip wore conductive material that is ordinary used for the stylus. Since the shaft of the pen used in these studies was made of plastic and does not conduct to the grip part, we winded a conductive sheet on the grip to react with a capacitance type touch screen. Inside the pen-type device, the vibrator (ALPS Inc., HAPTICTM Reactor) was embedded at the position of 2cm distance from the tip of the pen where participants gripped. The vibrator was small (35.0 mm Ã— 5.0 mm Ã— 7.5 mm) and light (about 5 g) enough not to prevent participants from moving the pen.
    - ãƒšãƒ³å‹è£…ç½®ã¯ã€é‡é‡ç´„ï¼’ï¼ï½‡ã€é•·ã•ç´„ï¼‘ï¼”ï¼ï½ï½ã§ã‚ã£ãŸã€‚ ãƒšãƒ³ã®æ¡ã‚Šéƒ¨ã®ç›´å¾„ã¯ç´„ï¼‘ï¼ï½ï½ã§ã‚ã£ãŸã€‚ ãƒšãƒ³å…ˆã¯ã€é€šå¸¸ã‚¹ã‚¿ã‚¤ãƒ©ã‚¹ã«ä½¿ç”¨ã•ã‚Œã‚‹å°é›»æ€§ææ–™ã‚’ç€ç”¨ã—ã¦ã„ã¾ã—ãŸã€‚ æœ¬ç ”ç©¶ã§ä½¿ç”¨ã—ãŸãƒšãƒ³ã®è»¸ã¯ãƒ—ãƒ©ã‚¹ãƒãƒƒã‚¯è£½ã§ã‚°ãƒªãƒƒãƒ—éƒ¨ã¨ã¯å°é€šã—ãªã„ãŸã‚ã€ã‚°ãƒªãƒƒãƒ—ã«å°é›»æ€§ã‚·ãƒ¼ãƒˆã‚’å·»ã„ã¦é™é›»å®¹é‡å¼ã‚¿ãƒƒãƒã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã«åå¿œã•ã›ãŸã€‚ ãƒšãƒ³å‹è£…ç½®ã®å†…å´ã«ã€å‚åŠ è€…ãŒæ¡ã£ãŸãƒšãƒ³ã®å…ˆç«¯ã‹ã‚‰ï¼’ï½ƒï½ã®è·é›¢ã®ä½ç½®ã«ãƒã‚¤ãƒ–ãƒ¬ãƒ¼ã‚¿ï¼ˆï¼¡ï¼¬ï¼°ï¼³ ï¼©ï½ï½ƒï¼ã€ï¼¨ï¼¡ï¼°ï¼´ï¼©ï¼£ï¼ˆç™»éŒ²å•†æ¨™ï¼‰ï¼²ï½…ï½ï½ƒï½”ï½ï½’ï¼‰ã‚’åŸ‹ã‚è¾¼ã‚“ã ã€‚ ãƒã‚¤ãƒ–ãƒ¬ãƒ¼ã‚¿ã¯å°ã•ãï¼ˆï¼“ï¼•ï¼ï¼ï½ï½Ã—ï¼•ï¼ï¼ï½ï½Ã—ï¼—ï¼ï¼•ï½ï½ï¼‰ã€å‚åŠ è€…ãŒãƒšãƒ³ã‚’å‹•ã‹ã™ã®ã‚’å¦¨ã’ãªã„ç¨‹åº¦ã«ååˆ†ã«è»½ã„ï¼ˆç´„ï¼•ï½‡ï¼‰ã§ã‚ã£ãŸã€‚

---

- When participants touched and moved the pen on the surface, the vibration signal was output from earphone jack of the tablet, and amplified by the amplifier, and vibrator embedded on the pen presented the vibration to the participantsâ€™ fingers
    - å‚åŠ è€…ãŒãƒšãƒ³ã‚’è¡¨é¢ã«è§¦ã‚Œã¦å‹•ã‹ã™ã¨ã€ã‚¿ãƒ–ãƒ¬ãƒƒãƒˆã®ã‚¤ãƒ¤ãƒ›ãƒ³ã‚¸ãƒ£ãƒƒã‚¯ã‹ã‚‰æŒ¯å‹•ä¿¡å·ãŒå‡ºåŠ›ã•ã‚Œã€ã‚¢ãƒ³ãƒ—ã§å¢—å¹…ã•ã‚Œã€ãƒšãƒ³ã«åŸ‹ã‚è¾¼ã¾ã‚ŒãŸãƒã‚¤ãƒ–ãƒ¬ãƒ¼ã‚¿ãŒå‚åŠ è€…ã®æŒ‡ã«æŒ¯å‹•ã‚’ä¸ãˆã¾ã—ãŸ
    
### 4.2 Task Design

- These studies used a within-participant design. Participants moved the pen-type device along the two different predefined path on screen in succession, while receiving either test or generated vibrational feedback. After that, participants tried to distinguish which stimulus was generated one. They also evaluated the realism of stimuli. In Generator Ex., generated signals were generated by feeding a label vector that represented each class into the generator. In E2E Ex., generated signals were generated by feeding a test image that represented each class into the encoder network. Corresponding class label texts or texture images were displayed on the touch screen. Participantsâ€™ task was the same in Generator Ex. and E2E Ex. except that what they saw on screen was class label texts or texture images.
    - ã“ã‚Œã‚‰ã®ç ”ç©¶ã¯å‚åŠ è€…å†…ãƒ‡ã‚¶ã‚¤ãƒ³ã‚’ä½¿ç”¨ã—ãŸã€‚ å‚åŠ è€…ã¯ã€ãƒ†ã‚¹ãƒˆã¾ãŸã¯ç”Ÿæˆã•ã‚ŒãŸæŒ¯å‹•ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å—ä¿¡ã—ãªãŒã‚‰ã€ãƒšãƒ³å‹ãƒ‡ãƒã‚¤ã‚¹ã‚’ç”»é¢ä¸Šã®2ã¤ã®ç•°ãªã‚‹å®šç¾©æ¸ˆã¿ãƒ‘ã‚¹ã«æ²¿ã£ã¦é€£ç¶šã—ã¦ç§»å‹•ã•ã›ã¾ã—ãŸã€‚ ãã®å¾Œã€å‚åŠ è€…ã¯ã©ã®åˆºæ¿€ãŒç”Ÿæˆã•ã‚ŒãŸåˆºæ¿€ã‚’åŒºåˆ¥ã—ã‚ˆã†ã¨ã—ã¾ã—ãŸã€‚ å½¼ã‚‰ã¯ã¾ãŸåˆºæ¿€ã®ç¾å®Ÿæ€§ã‚’è©•ä¾¡ã—ãŸã€‚ ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ä¾‹ã§ã¯ã€ç”Ÿæˆã•ã‚ŒãŸä¿¡å·ã¯ã€å„ã‚¯ãƒ©ã‚¹ã‚’è¡¨ã™ãƒ©ãƒ™ãƒ«ãƒ™ã‚¯ãƒˆãƒ«ã‚’ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã«ä¾›çµ¦ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚ ï¼¥ï¼’ï¼¥å®Ÿæ–½ä¾‹ã§ã¯ã€ç”Ÿæˆã•ã‚ŒãŸä¿¡å·ã¯ã€å„ã‚¯ãƒ©ã‚¹ã‚’è¡¨ã™ãƒ†ã‚¹ãƒˆç”»åƒã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«ä¾›çµ¦ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚ŒãŸã€‚ å¯¾å¿œã™ã‚‹ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ãƒ†ã‚­ã‚¹ãƒˆã¾ãŸã¯ãƒ†ã‚¯ã‚¹ãƒãƒ£ç”»åƒãŒã‚¿ãƒƒãƒã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã«è¡¨ç¤ºã•ã‚Œã¾ã—ãŸã€‚ å‚åŠ è€…ã®ä»•äº‹ã¯Generator Exã§ã‚‚åŒã˜ã§ã™ã€‚ ï¼¥ï¼’ï¼¥ ï¼¥ï½˜ã€‚ ãŸã ã—ã€ç”»é¢ä¸Šã«è¡¨ç¤ºã•ã‚Œã‚‹ã®ã¯ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ãƒ†ã‚­ã‚¹ãƒˆã¾ãŸã¯ãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚¤ãƒ¡ãƒ¼ã‚¸ã ã‘ã§ã—ãŸã€‚

---

- The procedure of one trial in participantâ€™s task is described in this paragraph. Participants moved the pen on a virtual texture surface from left to right for about 100 mm distance at fixed speed with their dominant hands. To control the movement speed and distance, the touch screen visualized a bar that indicated where and how much speed to move. According to the bar elongation, participants moved the pen approximately 100 mm distance in 1.6 seconds. Participants were told to hold the pen at the position where a vibrator was embedded.
    - ã“ã®æ®µè½ã§ã¯ã€å‚åŠ è€…ã®ä½œæ¥­ã«ãŠã‘ã‚‹1ã¤ã®è©¦è¡Œã®æ‰‹é †ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚å‚åŠ è€…ã¯ã€è‡ªåˆ†ã®åˆ©ãæ‰‹ã§ãƒšãƒ³ã‚’ä»®æƒ³ãƒ†ã‚¯ã‚¹ãƒãƒ£è¡¨é¢ä¸Šã§å·¦ã‹ã‚‰å³ã¸ç´„100 mmã®è·é›¢ã§ä¸€å®šã®é€Ÿåº¦ã§å‹•ã‹ã—ã¾ã—ãŸã€‚ç§»å‹•é€Ÿåº¦ã¨è·é›¢ã‚’åˆ¶å¾¡ã™ã‚‹ãŸã‚ã«ã€ã‚¿ãƒƒãƒã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã¯ç§»å‹•ã™ã‚‹å ´æ‰€ã¨é€Ÿåº¦ã‚’ç¤ºã™ãƒãƒ¼ã‚’è¦–è¦šåŒ–ã—ã¾ã—ãŸã€‚ãƒãƒ¼ã®ä¼¸ã³ã«ã‚ˆã‚‹ã¨ã€å‚åŠ è€…ã¯ãƒšãƒ³ã‚’1.6ç§’ã§ç´„100 mmç§»å‹•ã•ã›ã¾ã—ãŸã€‚å‚åŠ è€…ã¯ã€ãƒã‚¤ãƒ–ãƒ¬ãƒ¼ã‚¿ãŒåŸ‹ã‚è¾¼ã¾ã‚Œã¦ã„ã‚‹ä½ç½®ã«ãƒšãƒ³ã‚’æŒã¤ã‚ˆã†ã«è¨€ã‚ã‚Œã¾ã—ãŸã€‚ 

- After completing movement on two surfaces, they answered which stimulus was felt generated one by tapping one of the two answer buttons.    
    - 2ã¤ã®ã‚µãƒ¼ãƒ•ã‚§ã‚¹ä¸Šã§å‹•ãã‚’çµ‚ãˆãŸå¾Œã€2ã¤ã®ç­”ãˆãƒœã‚¿ãƒ³ã®ã†ã¡ã®1ã¤ã‚’ã‚¿ãƒƒãƒ—ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã€ã©ã¡ã‚‰ã®åˆºæ¿€ãŒç”Ÿæˆã•ã‚ŒãŸã¨æ„Ÿã˜ã‚‰ã‚Œã‚‹ã‹ç­”ãˆã¾ã—ãŸã€‚

- Besides, they answered the degree of realism for each stimulus by visual analogue scale (VAS) ratings [16] (Fig. 9 Right).   
    - ãã®ã†ãˆã€å½¼ã‚‰ã¯ã€è¦–è¦šçš„ã‚¢ãƒŠãƒ­ã‚°å°ºåº¦ï¼ˆVASï¼‰ã®è©•ä¾¡[16]ã«ã‚ˆã£ã¦å„åˆºæ¿€ã®ãƒªã‚¢ãƒªã‚ºãƒ ã®ç¨‹åº¦ã«ç­”ãˆã¾ã—ãŸï¼ˆå›³9å³ï¼‰ã€‚
    
- Participants rated the realism that they felt on an analogue scale in this testing method. 
    - å‚åŠ è€…ã¯ã€ã“ã®ãƒ†ã‚¹ãƒˆæ–¹æ³•ã§ã‚¢ãƒŠãƒ­ã‚°ã‚¹ã‚±ãƒ¼ãƒ«ã§æ„Ÿã˜ãŸç¾å®Ÿæ€§ã‚’è©•ä¾¡ã—ã¾ã—ãŸã€‚

- They answered the question â€œHow much realism did you feel?â€ by rating realism on a 100 mm line on the touch screen anchored by â€œdefinitely notâ€ on the left and â€œfelt realism extremelyâ€ on the right.
    - å½¼ã‚‰ã¯è³ªå•ã«ç­”ãˆã¾ã—ãŸã€Œã‚ãªãŸã¯ã©ã®ãã‚‰ã„ã®ãƒªã‚¢ãƒªã‚ºãƒ ã‚’æ„Ÿã˜ã¾ã—ãŸã‹ï¼Ÿã€ã¨ç­”ãˆã€100 mmã®ç›´ç·šã‚’ã‚¿ãƒƒãƒã‚¹ã‚¯ãƒªãƒ¼ãƒ³ä¸Šã§å›ºå®šã—ã€å³å´ã«ã€Œçµ¶å¯¾ã«ãªã„ã€ã¨å›ºå®šã—ã¾ã—ãŸã€‚

- They used the pen-type device to check on this line. The displayed order of test and generated stimuli in one trial was shuffled.  
    - å½¼ã‚‰ã¯ãƒšãƒ³å‹è£…ç½®ã‚’ä½¿ã£ã¦ã“ã®ç·šã‚’ãƒã‚§ãƒƒã‚¯ã—ãŸã€‚ 1å›ã®è©¦è¡Œã§è¡¨ç¤ºã•ã‚ŒãŸãƒ†ã‚¹ãƒˆã®é †åºã¨ç”Ÿæˆã•ã‚ŒãŸåˆºæ¿€ãŒã‚·ãƒ£ãƒƒãƒ•ãƒ«ã•ã‚Œã¾ã—ãŸã€‚

---

- Vibration signals that belonged to nine classes of textures that are modeled in Section 3 (Fig. 4) were prepared for this study. Test signals are randomly extracted from test dataset corresponds to each class, and generated signals are generated for each trial. Participants performed the trial ten times for each class. Therefore, each participant performed 180 trials in total for both Generator Ex. and in E2E Ex. E2E Ex. was conducted after Generator Ex. and these studies were held on separate days in order to prevent any satiation effects. To prevent sequential effects, the presentation order of these factors was randomly assigned and counter-balanced across participants.
    - ã“ã®ç ”ç©¶ã§ã¯ã€3ç« ï¼ˆå›³4ï¼‰ã§ãƒ¢ãƒ‡ãƒ«åŒ–ã•ã‚ŒãŸ9ç¨®é¡ã®ãƒ†ã‚¯ã‚¹ãƒãƒ£ã«å±ã™ã‚‹æŒ¯å‹•ä¿¡å·ã‚’ä½œæˆã—ã¾ã—ãŸã€‚ ãƒ†ã‚¹ãƒˆä¿¡å·ã¯å„ã‚¯ãƒ©ã‚¹ã«å¯¾å¿œã™ã‚‹ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«æŠ½å‡ºã•ã‚Œã€ç”Ÿæˆã•ã‚ŒãŸä¿¡å·ã¯å„è©¦è¡Œã«å¯¾ã—ã¦ç”Ÿæˆã•ã‚Œã¾ã™ã€‚ å‚åŠ è€…ã¯å„ã‚¯ãƒ©ã‚¹ã«ã¤ã10å›è©¦é¨“ã‚’å®Ÿæ–½ã—ãŸã€‚ ã—ãŸãŒã£ã¦ã€å„å‚åŠ è€…ã¯ä¸¡æ–¹ã®ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿Exã«ã¤ã„ã¦åˆè¨ˆ180å›ã®è©¦é¨“ã‚’å®Ÿæ–½ã—ãŸã€‚ ãŠã‚ˆã³ï¼¥ï¼’ï¼¥ ï¼¥ï½˜ã€‚ E2Eä¾‹ ç™ºé›»æ©Ÿä¾‹ã®å¾Œã«è¡Œã‚ã‚ŒãŸã€‚ ãã—ã¦ã“ã‚Œã‚‰ã®ç ”ç©¶ã¯é£½é£Ÿã®å½±éŸ¿ã‚’é˜²ããŸã‚ã«åˆ¥ã€…ã®æ—¥ã«è¡Œã‚ã‚ŒãŸã€‚ é€£ç¶šã—ãŸå½±éŸ¿ã‚’é˜²ããŸã‚ã«ã€ã“ã‚Œã‚‰ã®è¦ç´ ã®æç¤ºé †åºã¯ç„¡ä½œç‚ºã«å‰²ã‚Šå½“ã¦ã‚‰ã‚Œã€å‚åŠ è€…é–“ã§ç›¸æ®ºã•ã‚ŒãŸã€‚


### 4.3 Result

- Fig. 10 shows the percentage of correctly identifying which stimulus was generated. We call this value as â€œCorrect answer rateâ€. If this value is close to 50 %, it means that participants failed to distinguish test data from generated data.
    - **å›³ï¼‘ï¼ã¯ã€ã©ã®åˆºæ¿€ãŒç”Ÿæˆã•ã‚ŒãŸã‹ã‚’æ­£ã—ãè­˜åˆ¥ã—ãŸå‰²åˆã‚’ç¤ºã™ã€‚ ã“ã®å€¤ã‚’ã€Œæ­£è§£ç‡ã€ã¨å‘¼ã³ã¾ã™ã€‚ ã“ã®å€¤ãŒ50ï¼…ã«è¿‘ã„å ´åˆã¯ã€å‚åŠ è€…ãŒãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¨ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã‚’åŒºåˆ¥ã§ããªã‹ã£ãŸã“ã¨ã‚’æ„å‘³ã—ã¾ã™ã€‚**

- Thus, it is confirmed that our method could generate the vibrational stimuli that were close to the genuine stimuli.
    - ä»¥ä¸Šã®ã“ã¨ã‹ã‚‰ã€æœ¬æ‰‹æ³•ã¯æœ¬ç‰©ã®åˆºæ¿€ã«è¿‘ã„æŒ¯å‹•åˆºæ¿€ã‚’ç”Ÿæˆã§ãã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚
    
- The average and the standard error (SE) of â€œCorrect answer rateâ€ were 47.7 Â± 1.49 % for Generator Ex., and 48.2 Â± 2.49 % for E2E Ex. To investigate whether these rates were out of 50 %, we applied the Chi-Square goodness of fit test. It revealed that the rate of Carpet and Fine Foam condition in E2E Ex. were significantly lower than 50% (Carpet: p<0.01, Fine Foam: p<0.05).
    - ã€Œæ­£è§£ç‡ã€ã®å¹³å‡å€¤ã¨æ¨™æº–èª¤å·®ï¼ˆSEï¼‰ã¯ã€ç™ºé›»æ©Ÿä¾‹ã§47.7Â±1.49ï¼…ã€E2Eä¾‹ã§48.2Â±2.49ï¼…ã§ã‚ã£ãŸã€‚ ã“ã‚Œã‚‰ã®ç‡ãŒ50ï¼…ã‹ã‚‰å¤–ã‚Œã¦ã„ã‚‹ã‹ã©ã†ã‹ã‚’èª¿ã¹ã‚‹ãŸã‚ã«ã€ã‚«ã‚¤äºŒä¹—é©åˆåº¦æ¤œå®šã‚’é©ç”¨ã—ã¾ã—ãŸã€‚ ãã‚Œã¯E2E Exã®ã‚«ãƒ¼ãƒšãƒƒãƒˆãŠã‚ˆã³è‰¯ã„æ³¡ã®çŠ¶æ…‹ã®å‰²åˆã‚’æ˜ã‚‰ã‹ã«ã—ã¾ã—ãŸã€‚ ï¼•ï¼ï¼…ã‚ˆã‚Šæœ‰æ„ã«ä½ã‹ã£ãŸï¼ˆã‚«ãƒ¼ãƒšãƒƒãƒˆï¼šï½ ï¼œï¼ï¼ï¼ï¼‘ã€ç´°ã‹ã„æ³¡ï¼šï½ ï¼œï¼ï¼ï¼ï¼•ï¼‰ã€‚

---

- On the other hand, Fig.11 shows the results of how much realism participants felt for each class.
    - ä¸€æ–¹ã€å›³11ã¯ã€ã‚¯ãƒ©ã‚¹ã”ã¨ã«å‚åŠ ã—ãŸãƒªã‚¢ãƒªã‚ºãƒ ã®å‚åŠ è€…ã®å®ŸåŠ›ã®çµæœã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚

- The score of the realism of test data was 72.9 Â± 1.49 and that of generated data was 73.1 Â± 2.93 in Generator Ex.
    - Generator Exã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç¾å®Ÿæ€§ã®ã‚¹ã‚³ã‚¢ã¯72.9Â±1.49ã€ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã®ã‚¹ã‚³ã‚¢ã¯73.1Â±2.93ã§ã—ãŸã€‚ 

- In E2E Ex., the score of the realism of test data was 71.4 Â± 2.04 and that of generated data was 70.3 Â± 1.81.
    - E2E Ex ã§ã¯ã€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç¾å®Ÿæ€§ã®ã‚¹ã‚³ã‚¢ã¯71.4Â±2.04ã€ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ã‚¹ã‚³ã‚¢ã¯70.3Â±1.81ã§ã—ãŸã€‚
    
- We used a Studentâ€™s paired t-test to each texture condition, and revealed that there were significant differences between the average score of test and generated data for Bamboo in Generator Ex. (p=0.025), and Squared Aluminum Mesh, Bamboo, Card board in E2E Ex. (p=0.026, 0.025, 0.025). 
    - ãƒ†ã‚¯ã‚¹ãƒãƒ£ã®æ¡ä»¶ã”ã¨ã«ã‚¹ãƒãƒ¥ãƒ¼ãƒ‡ãƒ³ãƒˆã®tæ¤œå®š [Studentâ€™s paired t-test ] ã‚’ä½¿ç”¨ã—ãŸã¨ã“ã‚ã€Generator Exã§Bambooã®ãƒ†ã‚¹ãƒˆã®å¹³å‡ã‚¹ã‚³ã‚¢ã¨ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®é–“ã«æœ‰æ„å·®ãŒã‚ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚ ï¼ˆï½ ï¼ ï¼ï¼ï¼ï¼’ï¼•ï¼‰ã€
    - ãã—ã¦ ï¼¥ï¼’ï¼¥ ï¼¥ï½˜ ã«ãŠã„ã¦ã¯ã€Squared Aluminum Mesh, Bamboo, Card boardã§æœ‰æ„å·®ã‚ã‚Š ï¼ˆï½ ï¼ ï¼ï¼ï¼ï¼’ï¼–ã€ï¼ï¼ï¼ï¼’ï¼•ã€ï¼ï¼ï¼ï¼’ï¼•ï¼‰ã€‚ 
    
- There was no significant difference between the average score of test and generated data in total.
    - ãƒ†ã‚¹ãƒˆã®å¹³å‡ã‚¹ã‚³ã‚¢ã¨ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¨ã®é–“ã«ã¯ã€æœ‰æ„ãªå·®ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚
    

# â–  é–¢é€£ç ”ç©¶ï¼ˆä»–ã®æ‰‹æ³•ã¨ã®é•ã„ï¼‰

## x. è«–æ–‡ã®é …ç›®åï¼ˆRelated Workï¼‰


# 4.4 Discussion

- â€œCorrect answer rateâ€ of most texture conditions were almost 50%, thus participants could not distinguish test data from generated data. In the post questionnaire, all participants answered that they did not find the difference between the test stimulus and the generated stimulus. Therefore, it can be said that our system has the potential to generate the high realistic vibrotactile signals from given texture attributes or given texture images. â€œCorrect answer rateâ€ of Carpet and Fine Foam class in E2E Ex. were significantly lower than 50% so that participants tended to misunderstand the generated stimulus as an genuine stimulus for these two classes. On the contrary, there were no significant differences in the realism that participants felt between test and generated data in Carpet and Fine Foam classes. There was no correlation between the realism evaluation value and the discrimination rate of generated data.
    - ã»ã¨ã‚“ã©ã®ãƒ†ã‚¯ã‚¹ãƒãƒ£æ¡ä»¶ã®ã€Œæ­£è§£ç‡ã€ã¯ã»ã¼50ï¼…ã§ã‚ã£ãŸãŸã‚ã€å‚åŠ è€…ã¯ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¨ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã‚’åŒºåˆ¥ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ ãƒã‚¹ãƒˆã‚¢ãƒ³ã‚±ãƒ¼ãƒˆã§ã¯ã€å‚åŠ è€…å…¨å“¡ãŒãƒ†ã‚¹ãƒˆåˆºæ¿€ã¨ç”Ÿæˆã•ã‚ŒãŸåˆºæ¿€ã®é•ã„ã‚’è¦‹ã¤ã‘ã‚‰ã‚Œãªã‹ã£ãŸã¨å›ç­”ã—ã¾ã—ãŸã€‚ ã—ãŸãŒã£ã¦ã€æˆ‘ã€…ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ä¸ãˆã‚‰ã‚ŒãŸãƒ†ã‚¯ã‚¹ãƒãƒ£å±æ€§ã¾ãŸã¯ä¸ãˆã‚‰ã‚ŒãŸãƒ†ã‚¯ã‚¹ãƒãƒ£ç”»åƒã‹ã‚‰ç¾å®Ÿçš„ãªæŒ¯å‹•è§¦è¦šä¿¡å·ã‚’ç”Ÿæˆã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã¨è¨€ãˆã‚‹ã€‚ E2E Exã®ã‚«ãƒ¼ãƒšãƒƒãƒˆã¨ãƒ•ã‚¡ã‚¤ãƒ³ãƒ•ã‚©ãƒ¼ãƒ ã‚¯ãƒ©ã‚¹ã®ã€Œæ­£è§£ç‡ã€ å‚åŠ è€…ã¯ã“ã‚Œã‚‰ã®2ã¤ã®ã‚¯ãƒ©ã‚¹ã«å¯¾ã™ã‚‹æœ¬ç‰©ã®åˆºæ¿€ã¨ã—ã¦ç”Ÿæˆã•ã‚ŒãŸåˆºæ¿€ã‚’èª¤è§£ã™ã‚‹å‚¾å‘ãŒã‚ã£ãŸã®ã§ã€å‚åŠ è€…ã¯50ï¼…ã‚ˆã‚Šæœ‰æ„ã«ä½ã‹ã£ãŸã€‚ ãã‚Œã©ã“ã‚ã‹ã€ã‚«ãƒ¼ãƒšãƒƒãƒˆã¨ãƒ•ã‚¡ã‚¤ãƒ³ãƒ•ã‚©ãƒ¼ãƒ ã®ã‚¯ãƒ©ã‚¹ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¨ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã®é–“ã§ã€å‚åŠ è€…ãŒæ„Ÿã˜ãŸãƒªã‚¢ãƒªã‚ºãƒ ã«å¤§ããªé•ã„ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ ãƒªã‚¢ãƒªã‚ºãƒ è©•ä¾¡å€¤ã¨ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã®è­˜åˆ¥ç‡ã¨ã®é–“ã«ç›¸é–¢ã¯ãªã‹ã£ãŸã€‚


---

- Most scores about realism were over 60 and there was no significant difference between the scores of generated and test data in total. These results suggest that the generated vibrotactile stimuli had certain realism equivalent to the genuine stimuli. Focusing on the data for each class, the scores about realism were different between Generator Ex. and E2E Ex. This difference seems to be derived from the impression gap between texture attributes and images. Four out of ten participants answered in the post questionnaire that the impression of test image and label name were different, especially for Bamboo. Also, some participants said that it is difficult to imagine the texture surface from label name displayed in Generator Ex. These answers suggested that we should re-design the attribute axes, which we used class labels as they are in this study. For example, if we use some onomatopoeia as attribute axes, users can intuitively set and manipulate attributes and usability would be improved.
    - ãƒªã‚¢ãƒªã‚ºãƒ ã«é–¢ã™ã‚‹ã‚¹ã‚³ã‚¢ã®å¤§éƒ¨åˆ†ã¯60ã‚’è¶…ãˆã¦ãŠã‚Šã€ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã‚¹ã‚³ã‚¢ã®é–“ã«æœ‰æ„å·®ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã“ã‚Œã‚‰ã®çµæœã¯ã€ç”Ÿæˆã•ã‚ŒãŸæŒ¯å‹•è§¦è¦šåˆºæ¿€ãŒæœ¬ç‰©ã®åˆºæ¿€ã¨åŒç­‰ã®ã‚ã‚‹ãƒªã‚¢ãƒªã‚ºãƒ ã‚’æœ‰ã—ã¦ã„ãŸã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚å„ã‚¯ãƒ©ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹ã¨ã€ãƒªã‚¢ãƒªã‚ºãƒ ã«é–¢ã™ã‚‹ã‚¹ã‚³ã‚¢ã¯Generator Exã«ã‚ˆã£ã¦ç•°ãªã‚Šã¾ã—ãŸã€‚ ï¼¥ï¼’ï¼¥ ï¼¥ï½˜ã€‚ã“ã®é•ã„ã¯ã€ãƒ†ã‚¯ã‚¹ãƒãƒ£å±æ€§ã¨ã‚¤ãƒ¡ãƒ¼ã‚¸ã®é–“ã®å°è±¡ã®ã‚®ãƒ£ãƒƒãƒ—ã‹ã‚‰æ´¾ç”Ÿã™ã‚‹ã‚ˆã†ã§ã™ã€‚ 10äººä¸­4äººã®å‚åŠ è€…ãŒãƒã‚¹ãƒˆã‚¢ãƒ³ã‚±ãƒ¼ãƒˆã§ã€ãƒ†ã‚¹ãƒˆç”»åƒã¨ãƒ©ãƒ™ãƒ«åã®å°è±¡ã¯ç‰¹ã«Bambooã«å¯¾ã—ã¦ç•°ãªã‚‹ã¨å›ç­”ã—ã¾ã—ãŸã€‚ã¾ãŸã€å‚åŠ è€…ã®ä¸­ã«ã¯ã€Generator Exã«è¡¨ç¤ºã•ã‚Œã‚‹ãƒ©ãƒ™ãƒ«åã‹ã‚‰ãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚µãƒ¼ãƒ•ã‚§ã‚¹ã‚’æƒ³åƒã™ã‚‹ã®ã¯é›£ã—ã„ã¨è¿°ã¹ãŸã€‚ã“ã‚Œã‚‰ã®å›ç­”ã‹ã‚‰ã€å±æ€§ãƒ©ãƒ™ãƒ«ã‚’å†è¨­è¨ˆã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã¾ã—ãŸã€‚ã“ã®ç ”ç©¶ã§ã¯ã€ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã—ãŸã€‚ãŸã¨ãˆã°ã€å±æ€§è»¸ã¨ã—ã¦ã‚ªãƒãƒãƒˆãƒšã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ç›´æ„Ÿçš„ã«å±æ€§ã‚’è¨­å®šãŠã‚ˆã³æ“ä½œã§ãã€ä½¿ã„å‹æ‰‹ãŒå‘ä¸Šã—ã¾ã™ã€‚

- Users rated generated data significantly higher than test data for Squared Aluminum Mesh in E2E Ex. Five participants answered that they felt periodic vibrotactile stimuli like moving on the mesh as the generated stimuli, so it can be considered that the trained model has enhanced the characteristic attribute like a mesh too much.
    - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã€E2E Exã®Squared Aluminium Meshã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šã‚‚ã¯ã‚‹ã‹ã«é«˜ã„ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã‚’è©•ä¾¡ã—ã¾ã—ãŸã€‚ 5äººã®å‚åŠ è€…ã¯ã€ç”Ÿæˆã•ã‚ŒãŸåˆºæ¿€ã¨ã—ã¦ãƒ¡ãƒƒã‚·ãƒ¥ä¸Šã‚’å‹•ãã‚ˆã†ãªå‘¨æœŸçš„ãªæŒ¯å‹•è§¦è¦šåˆºæ¿€ã‚’æ„Ÿã˜ãŸã¨å›ç­”ã—ãŸã®ã§ã€è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ãƒ¡ãƒƒã‚·ãƒ¥ã®ã‚ˆã†ãªç‰¹å¾´çš„ãªå±æ€§ã‚’å¼·åŒ–ã—ã™ããŸã¨è€ƒãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
